<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用CDN加速你的博客]]></title>
    <url>%2F20190417%2F27_cdn_for_hexo%2F</url>
    <content type="text"><![CDATA[上一篇如何在GitHub、GitLab、Gitee、Coding上部署Hexo折腾了一番后发现，GitLab的访问速度还是不尽人意，而最近（2019.04）GitHub反而更好了，coding也挺快了，但由于在博客中会有一些短视频打开速度超级慢（出于某些原因，不想放B站），所以又折腾了CDN加速… 首先需要一个已备案域名 关于CDNCDN(Content Delivery Network)内容发布网络，基本思路就是将你网站放置在各地节点服务器，用户访问时找最近的节点服务器获取数据，达到加速的目的。具体就不解释了，我也是不专业的，有兴趣自行谷歌。 国内提供CDN加速的大厂有很多，阿里云、腾讯云、百度云、七牛云等等，我只试了腾讯云与七牛云，其他可以自行测试。 腾讯云：每月10GB免费流量包，新用户前6个月每月赠送50GB 七牛云：每月10GB免费流量包【CDN-HTTP】 对于个人网站来说应该绰绰有余 实际使用下来，腾讯云太不稳定了…最终用的七牛云 用七牛云CDN加速你的博客先看效果，祖国大好河山一片绿。没加速之前是GitLab，最近这段时间GitLab确实不行啊，GitHub反而好很多。 注册七牛云（不介意的话，用一下我的邀请链接） 添加融合CDN 域名类型：普通域名 加速域名：www.zydarchen.top 通信协议：HTTPS，然后点击SSL 证书管理，上传自有证书（不知道怎么获取的看一下上篇） 源站配置：源站域名——zydarchen.gitlab.io（填写GitHub Pages/GitLab Pages/Coding Pages域名） 域名防盗链可以打开，其他的默认即可 创建 成功创建之后得到一个CNAME，将其添加到你域名的默认解析中，并暂停原有的默认解析。这里我国外解析还是没变，国外选路到GitHub Pages，国内默认到七牛云CDN 由于在七牛云上已经做了一次SSL证书认证，需要把原有的证书认证暂停或者删除（这里被坑了好久）记录类型：TXT主机记录：_dnsauth记录值：201902180000005****lif 等待域名解析生效即可，看一下效果，起飞 最后需要注意一点，由于CDN的存在，可能导致更新文章之后网站没有实时更新，这个时候在七牛云上刷新一下缓存即可 用七牛云对象存储做图床其实我一开始折腾的目的是图床的…图床的作用就不废话了，可以看这篇Hexo-Next搭建个人博客（使用图床）我是因为博客中有些小视频，不想放B站，直接放博客上又打开特别慢 新建存储空间 测试域名只能用30天，所以还是要绑定自己的域名 加速域名：pic.zydarchen.top 源站配置：七牛云存储 其他跟之前的配置差不多 在内容管理页面上传图片/视频，其他配置没啥特殊的，稍微过一眼都能看懂，图片样式、转码样式啥的看个人喜好，支持免费自动水印挺好的 将博客中的图片链接替换成七牛云上的图片外链即可 写博客的时候推荐用图床工具PicGo、iPic 2019.05.07更新之前没看清楚，原来七牛云的免费额度是【CDN-HTTP】，也就是你的博客使用HTTPS协议的话是享受不到这个免费额度的，具体费用在这个页面 &gt;&gt;&gt; 融合CDN价格详情 整理一下几大厂商的CDN方案 资费介绍页面 免费额度 是否支持HTTPS 额外限制 注册邀请链接 七牛云 10GB/月 按量付费支持 / &gt;&gt;&gt; 点击注册 腾讯云 10GB/月 免费支持 加了腾讯云CDN没有感觉多大加速 / 百度云 10GB/天 年费付费支持 巨贵… / 又拍云 15GB/月 免费支持 加入又拍云联盟，并在网站底部放置logo &gt;&gt;&gt; 点击注册]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕设论文相关小技巧]]></title>
    <url>%2F20190308%2F26_word_tips%2F</url>
    <content type="text"><![CDATA[写毕业论文过程中的一些小技巧，希望对你有用。 公式自动编号 MathType Tips 图片自动编号 使用Mendeley插入参考文献 插入矢量图 善用样式这点只是强调，大多数人应该都懂，不赘述。先把论文的样式做好，后面真的可以省很多事，一般也不需要自己从头开始，在往届的模板上根据今年新要求改即可。 2019届模板下载提取码：xdvv 公式自动编号首先，绝大多数本硕博论文、专利要求使用MathType (office自带Alt+=真的挺好用的)，下面基于MathType介绍 破解版下载：Mathtype-6.9b+Key提取码：bcew 点击MathType - Right numbered 写完公式就可以发现已经自动编号了 点击MathType - (1)Insert Number右侧的小箭头，再点击Format...，在Format Equation Numbers界面进行如下配置 一般毕业论文公式需要按章节排序，在每一章的开头处，点击MathType - Chapters&amp;Sections右侧的小箭头，再点击Insert Next Chapter Break 如果在论文中引用公式，“如公式(1-1)所示”之类的，最好使用引用链接点击MathType - Insert Reference，双击要引用的公式编号，自动生成。当然，不使用这个功能也没问题，就是后期如果需要对版面进行大调整，可能麻烦些。 视频 (function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","loop":true,"video":{"url":"https://image.zydarchen.top/video/26_mathtype.mp4","pic":"https://image.zydarchen.top/video/26_mathtype.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})() MathType Tips 等号对齐Format - Align at &lt;&gt;=... 多行多列使用Matrix对齐，大概是这样的效果 MathType默认函数非斜体MathType中像”max”这样的函数是非斜体的，选中然后点击Style - Variable 图片自动编号第一种做法是把标题样式整成列表样式，但是太麻烦了，还有Bug…推荐的简单做法是 图片右键 -&gt; 插入图注 -&gt; 新建标签，新建多个标签分别是“图1-”、“图2-” 选择所在章节的标签直接插入 使用样式修改题注格式（可以直接把题注样式改成想要的样式，避免每次修改） 如果在论文中引用图片，“如图1-1所示”之类的，最好使用引用链接点击插入-交叉引用，选择引用的题注，选择引用内容为“仅标签和编号” 第4点看个人喜好，好处就是当论文内容需要进行大调整时，不要去修改类似“如图1-1”这样的字样，直接更新域即可；缺点是我打印的时候交叉引用的地方会出现框框，不知道是不是个例，解决方案是打印之前Ctrl+A全选，Ctrl+Shift+F9取消链接，然后正常导出PDF去打印即可（打印要用PDF，这点不用强调了吧） 视频 (function(){var player = new DPlayer({"container":document.getElementById("dplayer1"),"theme":"#FADFA3","loop":true,"video":{"url":"https://image.zydarchen.top/video/26_pic.mp4","pic":"https://image.zydarchen.top/video/26_pic.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})() 自动插入参考文献插入参考文献的方式很多，手动添加、使用脚注、交叉引用、使用插件等等。我的建议是，在开始写论文的时候就选一种插件，适应之后，后期几乎不用管参考文献的事情。另外，如果是一开始没有用插件，而临近提交的时候才整理参考文献，那就花点精力直接Google学术+Word脚注吧。插件很多：Mendeley、Zotero、EndNote等等，我用的是Mendeley，这里只介绍Mendeley 关于Mendeley感觉又可以写一篇，这里简单提一下优点： 跨平台 文献自动重命名，自动归类 自动补全文献信息 Word插件自动添加参考文献 自定义参考文献样式 Web插件浏览器导入文献（个人用得少） 相关文献推荐（还挺准的，但我推荐Google学术订阅功能） 云端存储功能（但是有时会替换掉我的笔记，我用坚果云代替） 与其他软件兼容，如Researcher Mendeley使用 安装Mendeley，Word以及Web插件Tools -&gt; Install MS Word PluginTools -&gt; Install Web Importer 在Mendeley中导入参考文献方法一：Google学术+Web插件，一键导入Mendeley方法二：下载PDF，放入Watched Folders文件夹，在File - Watch Folder... - Watched Folders设置方法三：对于一些网页、博文等，直接手动添加，File - Add Entry Manually... Mendeley最好用的地方在于，我们下载的文档一般是1-s2.0-S0968090X18302651-main.pdf，Mendeley自动帮你转成类似Year_Author_Title.pdf这样自定义的格式 Mendeley会根据自己的库填充相关信息，一般是准确的，但稳妥起见还是得检查一遍是否完整，手动修改 Word文档中要插入参考文献的位置点击引用 - Insert Bibliography，Style的位置选择论文需要的样式，一般要求Chinese Std GB/T 7714-1987（谷歌学术是Chinese Std GB/T 7714-2005），蛋疼的我们学校还要在87版的基础上去掉句尾的结束符，我改了模板，如果学校要求没变可以直接用。chinese-gb7714-1987-zydarchen链接 在论文需要插入参考文献的位置点击引用 - Insert Citation即可跳转到Mendeley插入，描述太麻烦，直接看视频吧。 如果参考文献有变动，记得更新域，或者引用 - Refresh 视频 (function(){var player = new DPlayer({"container":document.getElementById("dplayer2"),"theme":"#FADFA3","loop":true,"video":{"url":"https://image.zydarchen.top/video/26_mendeley.mp4","pic":"https://image.zydarchen.top/video/26_mendeley.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})() 插入矢量图 折线图、柱状图等Excel可以画的图一律使用Excel，画完之后复制Excel里的图片，在Word里右键选择“使用目标主题和嵌入工作簿”，这样可以保证数据跟图一起导入Word，后期需要修改图的时候直接在Word里面改数据，而不用担心原始数据丢失。选中图表，点击图表工具 - 设计 - 编辑数据 尽量使用Visio画图，风格配色稍微统一一下 （这点估计强迫症才会去折腾了）matplotlib可以导出pdf或者eps，再用Adobe Illustrator或者CorelDRAW转成wmf。其他图片也尽量找到矢量图再转成wmf]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Word</tag>
        <tag>Mendeley</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的2018校招]]></title>
    <url>%2F20190223%2F25_campus2018%2F</url>
    <content type="text"><![CDATA[Welcome to my blog, enter password to read. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Offer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在GitHub、GitLab、Gitee、Coding上部署Hexo]]></title>
    <url>%2F20190219%2F24_gitlab_hexo%2F</url>
    <content type="text"><![CDATA[起因是近期（近几个月）Coding Pages服务的页面打开速度简直龟速，官方说是资源分配问题以及用户增加之后带宽不够。（总觉得是腾讯云的锅）以前博客部署在GitHub+Coding，默认线路是Coding，境外IP分配到GitHub，现在不得已另谋出路，就试试目前各大Pages服务提供商 结论先行目前(2019.02)用GitLab，有条件的自己搭个服务器才是最终解决方案。 免费私有项目 自定义域名 CI/CD 国内访问速度 服务器 Ping GitHub 是，但私有后无法开启Pages服务 是 否 ⭐⭐ 荷兰 167ms GitLab 是 是 是 ⭐⭐⭐ 美国 317ms Gitee 是 99/年 否 ⭐⭐⭐⭐ 湖北 19ms Coding 是 是 否 ⭐ 香港 3002ms 制表于2019.02.25，Ping数据存在比较大的波动 GitHub网上教程很多，不用多说了 Coding参考hello_blog Q12跟GitHub差不多，注意在source/下放置空白文件Staticfile Gitee 跟GitHub差不多，值得注意的是，项目中有html文件之后，才能在服务中找到Gitee Pages 一开始有一个月的Gitee Pages Pro试用版，可以个性化域名，到期之后需要支付99/年进行升级 如需配置域名证书，请到域名提供商下载。我的域名在阿里云买的，这里提供阿里云的下载流程 登陆阿里云，进入控制台，左侧选择域名 点选域名，查看域名基本信息，可以看到有一项免费开启SSL证书 进去之后选择免费的Symantec申请 几分钟之后在证书列表可以看到申请到的证书，下载其他得到一个zip文件，里面有后缀.key以及.pem的两个文件 用文本编辑器打开这两个文件，并复制到Gitee Pages GitLab GitLab Pages 搭建Hexo教程 GitLab的搭建与其他平台均不相同，因其独有的CI/CD，我们会把博客源码直接托管在GitLab上，由GitLab Pages启动Hexo服务，这样的好处就是当你在多台设备上更新博客时，每台电脑上仅需配置Git即可；缺点是对插件的定制化要麻烦些最好的教程当然是官方文档GitLab Pages，下面是我一些简单折腾记录 fork hexo项目（GitLab Pages examples还有其他examples） 在项目左侧Settings-&gt;General-&gt;Advanced删除fork关系 将GitLab设置Settings-&gt;Profile-&gt;Main settings-&gt;Preferred language修改为简体中文，可以默认显示中文哟 修改项目信息，最好将Project name跟Path均设置为username.gitlab.io，不然后续有坑（被坑过，搞了我一晚上原来是这个问题…） 修改.gitlab-ci.yml文件，可以参考我安装的插件 123456789101112131415161718192021222324252627image: node:8.11.2pages: cache: paths: - node_modules/ script: - npm install hexo-cli -g # 字数统计 - npm install hexo-symbols-count-time --save # 搜索 - npm install hexo-generator-searchdb --save # sitemap - npm install hexo-generator-sitemap --save - npm install hexo-generator-baidu-sitemap --save # 置顶功能 - npm uninstall hexo-generator-index --save - npm install hexo-generator-index-pin-top --save # 加密功能 - npm install hexo-blog-encrypt --save - hexo deploy artifacts: paths: - public only: - master 稍等片刻（几分钟），就可以在https://username.gitlab.io/页面看到Hexo的Hello World，如果你的Project name跟Path不是username.gitlab.io，那么请打开https://username.gitlab.io/project_name，同时要把站点_config.yml中的root修改为Project name 最后把其他平台的内容直接搬运过来即可。将项目git clone到本地，拷贝source和themes文件夹以及站点_config.yml进去，再push上去 由于是源码直接放在GitLab上，可能存在隐私数据，最好将项目设置为私密 在项目左侧Settings-&gt;Pages中点击New Domain配置个性化域名，根据提示在域名提供商的DNS解析中配置CNAME与TXT，这都是老生常谈了。如果勾选了Force domains with SSL certificates to use HTTPS则需提供域名证书，方法与上文的Gitee相同 总结目前用GitLab因其独有的CI/CD，国内外访问速度均可，下一步有精(jin)力(qian)再来搞服务器博客地址 www.zydarChen.top zydarChen.github.io zydarChen.gitlab.io zydarChen.gitee.io zydarChen.coding.me 4.19更新折腾了一番后发现，GitLab的访问速度还是不尽人意，而最近（2019.04）GitHub反而更好了，coding也挺快了，但由于在博客中会有一些短视频打开速度超级慢（出于某些原因，不想放B站），所以又折腾了CDN加速..使用CDN加速你的博客]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[软件下载安装备忘]]></title>
    <url>%2F20181126%2F23_software%2F</url>
    <content type="text"><![CDATA[Welcome to my blog, enter password to read. Incorrect Password! No content to display! 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]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Tensorflow或Keras时对GPU内存限制]]></title>
    <url>%2F20181016%2F22_tensorflow_gpu%2F</url>
    <content type="text"><![CDATA[跑Keras 或者 Tensorflow时默认占满所有GPU内存，这时如果想再开一个进程，或者别人想开一个进程都挤不上来，所以必须限制GPU内存 最好的资料还是官方文档 visible_device_list指定使用哪块显卡 per_process_gpu_memory_fraction分配到的内存占总内存量的比例 allow_growth根据运行时的需要来分配GPU内存，刚开始分配很少内存，随着Session开始运行并需要更多GPU内存时会自动扩展，但后续不会释放内存 per_process_gpu_memory_fraction与allow_growth两种方法二选一即可。一般用allow_growth即可，如果你能准确预估你的程序需要多大显存，推荐per_process_gpu_memory_fraction123456789# 将下面代码放在.py文件开头import tensorflow as tfconfig = tf.ConfigProto()config.gpu_options.visible_device_list = '0'# config.gpu_options.per_process_gpu_memory_fraction = 0.2config.gpu_options.allow_growth = Truesess = tf.Session(config=config)# from keras import backend as K# K.set_session(sess) 个人习惯而言，每个项目有个配置文件config.py，里面写好基本配置函数，如GPU配置，路径配置等。set_gpu()函数，自动识别是否有显卡，有显卡则指定空余内存多或者GPU使用低的显卡，并设置分配比例12345678910111213141516171819202122232425262728293031def set_gpu(ratio=0, target='memory'): """ 配置GPU，0表示自适应，(0, 1]表示显存占比 :param ratio: :param target: 选择显存大的卡还是GPU利用率低的卡 :return: """ command1 = "nvidia-smi -q -d Memory | grep -A4 GPU | grep Free | awk '&#123;print $3&#125;'" command2 = "nvidia-smi -q | grep Gpu | awk '&#123;print $3&#125;'" memory = list(map(int, os.popen(command1).readlines())) gpu = list(map(int, os.popen(command2).readlines())) if memory and gpu: # 如果没有显卡，memory，gpu均为[] if target == 'memory': num = (1, 0)[memory[0] &gt; memory[1]] else: num = (0, 1)[gpu[0] &gt; gpu[1]] print('&gt;&gt;&gt; Free Memory : GPU0 %6d MiB | GPU1 %6d MiB' % (memory[0], memory[1])) print('&gt;&gt;&gt; Volatile GPU-Util : GPU0 %6d %% | GPU1 %6d %% ' % (gpu[0], gpu[1])) print('&gt;&gt;&gt; Using GPU%d' % num) import tensorflow as tf config = tf.ConfigProto() config.gpu_options.visible_device_list = str(num) # 选择GPU if ratio == 0: config.gpu_options.allow_growth = True else: config.gpu_options.per_process_gpu_memory_fraction = ratio sess = tf.Session(config=config) from keras import backend as K K.set_session(sess) else: print('&gt;&gt;&gt; Could not find the GPU') 指定显卡的另外两种方法 配进环境变量 1export CUDA_VISIBLE_DEVICES=0 使用os 12import osos.environ["CUDA_VISIBLE_DEVICES"] = '0' 查看GPU使用情况 watch -n 1 nvidia-smi每秒刷新 nvidia-smi]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Keras</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Keras LSTM的stateful]]></title>
    <url>%2F20180925%2F21_stateful_LSTM%2F</url>
    <content type="text"><![CDATA[Keras LSTM的stateful非常容易用错，前段时间研究了一下，记记笔记~如有错误，欢迎评论指出~ 结论先行 绝大多数情况下，用stateless就行了 官方FAQ 最好的学习资料永远是官方文档 使RNN具有状态意味着每批样品的状态将被重新用作下一批样品的初始状态。当使用有状态 RNN 时，假定： 所有的批次都有相同数量的样本 如果x1和x2是连续批次的样本，则x2[i]是x1[i]的后续序列，对于每个i 要在 RNN 中使用状态，你需要: 通过将batch_size参数传递给模型的第一层来显式指定你正在使用的批大小。例如，对于10个时间步长的32样本的batch，每个时间步长具有16个特征，batch_size = 32 在RNN层中设置stateful = True 在调用fit()时指定shuffle = False 有点绕，我给翻译翻译 假设Timestep=5，batch_size=2 X1和X2就是连续的两个批次，X2[i]是X1[i]的后续序列，也就是说，床前明月光后面是疑是地上霜 光的状态会传递到疑作为初始状态，也就是用光输出的(h, c)来初始化疑的(h, c) 那就不难理解为什么“所有的批次都有相同数量的样本”，如果不同批次的样本数不同，那上一批次传过来的(h, c)将没人接手 进而，Keras文档说用stateful需要指定batch_size也没毛病，不指定的话，Keras默认容忍最后一个批次样本数不同。例如，samples=9,batch_szie=2，那么默认分成5批，最后一批只有1个样本 下一个问题，shuffle shuffle = True会在每个epoch开始之前打乱训练集数据顺序，使用stateful LSTM肯定要设置shuffle = False，不然光可能传给汗不就乱套了 官方examples 还是那句话，最好的学习资料在官方，墙裂建议好好跑跑这份代码，以下只是我的笔记~ 参数说明 input_len序列长度 tsteps移动平均的步长e.g. if tsteps=2 and input=[1, 2, 3, 4, 5], then output=[1.5, 2.5, 3.5, 4.5] lahead理解成模型的timestep就行了 结论 When lahead &lt; tsteps, only the stateful LSTM converges When lahead &gt;= tsteps, both the stateful and stateless LSTM converge 我再来翻译翻译 任务的实质就是，用lahead个前序数据去预测步长为tsteps的平均值 如果lahead=3, tsteps=2, lahead &gt;= tsteps，预测值仅与当前时刻和上一时刻的输入有关，而我们拿三个时刻的数据建模，肯定收敛 如果lahead=1, tsteps=2, lahead &lt; tsteps，预测值仅与当前时刻和上一时刻的输入有关，而我们只拿了当前时刻数据建模，使用stateless肯定不能收敛，而使用stateful，由于能考虑上一时刻的输入，故收敛 实际效果 代码&amp;结果 (tsteps, lahead, batch_size) Stateful RMSE Stateless RMSE 2, 1, 1 0.014813 0.031049 2, 2, 1 0.011407 0.000185 2, 2, 2 0.010075 0.000017 2, 1, 2 0.028951 0.029062 tsteps=2, lahead=1, batch_size=1，理论上stateful能收敛，stateless不能收敛，RMSE(stateful) &lt; RMSE(stateless)没问题 tsteps=2, lahead=2, batch_size=1，理论上都能收敛，stateless效果很好 tsteps=2, lahead=2, batch_size=2，在上次实验的基础上，batch_size调整为2，stateful似乎好了一点点 tsteps=2, lahead=1, batch_size=2，与实验1对照，stateful似乎变差了很多，为什么呢？因为lahead不等于batch_size时，LSTM状态没有传递 在本例中，需要保证lahead = batch_size，才能保证stateful正确传递状态，为什么呢？请看图~明白了吧~ 非官方FAQ LSTM学习哪段序列的关系？Timestep内的序列关系 Jason的博文Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras为什么说如果所有sample一个batch，则LSTM能很好地考虑上下文信息仔细看他代码，偷偷把epoch调成5000了，效果当然好（被坑过）…而且他的例子太简单了，timestep=1，还算个锤子LSTM 关于Tensorflow中BATCH_SIZE,CELL_SIZE的讨论为什么说“BATCH_SIZE * TIME_STEPS 必须等于数据长度”个人觉得有误，只有在使用stateful时，才需要对batch_size严格指定，最好的例子就是官方examples（如果是我理解错，请指出） stateful LSTM为什么要指定batch_size？保证每个batch的样本数相同 stateful LSTM训练完一个epoch为什么要手动重置网络？如果不重置，就会将上个epoch最后一个batch的状态传递给下个epoch的第一个batch，这明显不是我们乐意见到的 需要stateful么？绝大多数情况下，用stateless就行了 参考目录 Keras之stateful LSTM全面解析+实例测试 Stateful LSTM in Keras Stateful and Stateless LSTM for Time Series Forecasting with Python Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras keras/examples/lstm_stateful.py How can I use stateful RNNs?]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS224N笔记-Lecture2 Word Vectors]]></title>
    <url>%2F20180727%2F20_cs224n_2%2F</url>
    <content type="text"><![CDATA[Word meaning Word2Vec introduction Research highlight Word2Vec objective function gradients Optimization refresher CS224n笔记2 词的向量表示：word2vec Word meaning 在过去的几个世纪里，计算机一直使用分类(taxonomy)词典处理词语的意思，比如WordNet词库 过去的离散表示(discrete representation)会存在一定的问题 即使是再完备的词典，也会忽略细微的差别，比如同义词 缺少新词 主观性强 需要大量人力 计算机难于理解词的相似性 无论是规则学派，还是统计学派，绝大多数NLP学家都将词语作为最小单位。事实上，词语只是词表长度的one-hot向量，这是一种localist representation 通过一个单词的上下文可以得到它的意思，这是现代统计自然语言处理最成功的思想之一 “You shall know a word by the company it keeps”——J. R. Firth 1957: 11 distributed representations与symbolic representations（localist representation、one-hot representation）相对；discrete representation则与后者及denotation的意思相似。切不可搞混distributed和discrete这两个单词 Basic idea of learning neural network word embeddings 定义一个以预测某个单词的上下文模型：p(context|w\_t)= 损失函数定义如下：J=1-p(w\_{-t}|w\_t) 这里的$w_{-t}$表示$w_t$的上下文，然后在一个大型语料库中的不同位置得到训练实例，调整词向量，最小化损失函数 Word2Vec introduction Word2Vec的主要思路 两种算法 Skip-grams(SG)：预测上下文 Continuous Bag of Words(CBOW)：预测目标词 两种稍微高效的训练方法 Hierarchical softmax Negative sampling]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>CS224n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL快速参考]]></title>
    <url>%2F20180630%2F19_quick_sql%2F</url>
    <content type="text"><![CDATA[Structured Query Language，结构化查询语言 基础12345678910111213SHOW DATABASES;USE database_name;SHOW COLUMNS FROM table_name; # 创建用户CREATE USER 'chen'@'%' IDENTIFIED [WITH mysql_native_password] BY 'chen123';# 检查用户SELECT user, host, plugin, authentication_string FROM mysql.user\G;# 授权GRANT ALL PRIVILEGES ON *.* TO 'chen'@'%';GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,ALTER ON *.* TO 'chen'@'%';# 查看权限SHOW GRANTS for 'chen'@'%'; SELECT1234567891011121314151617SELECT column_name(s)FROM table_name;SELECT [DISTINCT] column_name(s)FROM table_nameWHERE column_name operator value[AND|OR column_name operator value]ORDER BY column_name(s) ASC|DESC[LIMIT number];SELECT column_name(s)FROM table_nameWHERE column_name IN (value1,value2,...);SELECT column_name(s)FROM table_nameWHERE column_name BETWEEN 'A' AND 'H'; LIKE1234567891011121314SELECT column_name(s)FROM table_nameWHERE column_name LIKE pattern;# pattern'%a' # 以a结尾的数据'a%' # 以a开头的数据'%a%' # 含有a的数据'_a_' # 三位且中间字母是a的'_a' # 两位且结尾字母是a的'a_' # 两位且开头字母是a的# REGEXPSELECT * FROM WebsitesWHERE name REGEXP '^[A-H]'; INSERT123456789101112INSERT INTO table_nameVALUES (value1, value2, ...);INSERT INTO table_name (column_name1, column_name2, ...)VALUES(value1, value2, ...);INSERT INTO table2(column_name(s))SELECT column_name(s)FROM table1; UPDATE123UPDATE table_nameSET column1=value1, column2=value2, ...WHERE some_column=some_value; DELECT12345678DELECT FROM table_nameWHERE some_column=some_value;DELECT * FROM table_name;TRUNCATE table_name;DROP table_name; JOIN1234SELECT column_name(s)FROMtable1 INNER|LEFT|RIGHT|FULL JOIN table2ON table1.column_name=table2.column_name;\ UNION123SELECT column_name(s) FROM table1UNION [ALL]SELECT column)name(s) FROM table2; CREATE TABLE123456789101112CREATE TABLE persons( PersonID int NOT NULL AUTO_INCREMENT, StudentID int, LastName varchar(255), FirstName varchar(255), Address varchar(255) DEFAULT 'GuangZhou', CHECK (PersonID&gt;0), UNIQUE (StudentID), PRIMARY KEY (PersonID), FOREIGN KEY (StudentID) REFERENCES student(StudentID) ); ALTER TABLE1234567891011ALTER TABLE personsADD|DROP UNIQUE (PersonID);ALTER TABLE personsDROP PRIMARY KEY;ALTER TABLE personsADD CHECK (PersonID&gt;0);ALTER TABLE personsALTER Address SET DEFAULT 'GuangZhou'; VIEW1234CREATE VIEW view_name ASSELECT column_name(s)FROM table_nameWHERE condition; 函数12345678SELECT AVG(column_name) FROM table_name;SELECT COUNT(column_name) FROM table_name;SELECT column_name, aggregate_function(column_name)FROM table_nameWHERE column_name operator valueGROUP BY column_name; PyMySQL fetchone(): 该方法获取下一个查询结果集。结果集是一个对象 fetchall(): 接收全部的返回结果行. rowcount: 这是一个只读属性，并返回执行execute()方法后影响的行数。 重要函数 cursor(cursor = None): 创建一个游标 commit(): 事务提交，如果没有设为自动提交，则每次操作后必须提交事务，否则操作无效。 rollback(): 操作出错时，可以用这个函数回滚到执行事务之前 close(): 关闭连接 123456789101112# pymysql不支持caching_sha2_password加密，需指定mysql_native_password# create user 'wang'@'localhost' identified with mysql_native_password by 'wang123';# user需要权限# grant all privileges on *.* to 'wang'@'localhost';import pymysqldb = pymysql.connect(host='localhost', user='wang', password='wang123', db='world')cursor = db.cursor()cursor.execute('SELECT VERSION()')# db.commit() # 像数据库提交data = cursor.fetchone()print ('Database version : %s ' % data)db.close() 备忘1where add_time &gt;= UNIX_TIMESTAMP(to_date('20180101', 'yyyymmdd')) 更多函数 日期时间 to_date, 将字符类型按一定格式转化为日期类型, to_date(‘2004-11-27’, ‘yyyy-mm-dd’) to_char, 将日期类型转化为字符类型, to_char(sysdate, ‘yyyymmdd’) 12# 星期几to_char(to_date('2002-08-26','yyyy-mm-dd'),'day') date_format(date, format) from_unixtime(inux_timestamp, format) unix_timestamp(date) 数据类型转化，CAST (expression AS data_type)，SELECT CAST(‘12.5’ AS decimal(9,2)) # 精度9，小数点位数2 TRIM()，移除头尾空白 正则，select regexp_substr(a, ‘[0-9]+’)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS224N笔记-Lecture1 Introduction]]></title>
    <url>%2F20180612%2F18_cs224n_1%2F</url>
    <content type="text"><![CDATA[What is Natural Language Processing？ What’s special about human language? What’s Deep Learning? Why is NLP hard？ Deep NLP = Deep Learning + NLP What is Natural Language Processing？ 自然语言处理是计算机科学、人工智能以及语言学的交叉学科 自然语言处理的目标是让计算机理解人类语言，以完成有意义的任务，如机器翻译或QA等。 NLP Levels speech or text annlysis morphological analysis，形态分析 syntactic analysis，句法分析 semantic interpretation，语义分析 discourse processing，对话处理（理解上下文） What’s special about human language? 人类语言是一种离散/符号/类别信号系统 What’s Deep Learning? 深度学习是机器学习的一种 机器学习需要人工设计特征，然后把特征交给某个机器学习算法，机器为这些特征调整找到合适的权值，以生成最合适的模型；事实上，在这一过程中，是人类在学习，而机器只不过是解数值优化的题目而已。 Machine Learning in Practice = Describing your data with features a computer can understand (Domain specific, requires Ph.D. level talent) + Learning algorithm (Optimizing the weights on features) 表征学习（Representation Learning）是指通过对原始数据的学习，自动生成特征。 深度学习是表征学习的一部分，使用多层的表征学习（learned representations），故称为深度学习。 Reasons for Exploring Deep Learning 人工构建特征往往过去具体，而且需要大量时间去设计和验证 学习特征自适应能力强，而且学习速度快 能处理监督以及无监督问题 使人们兴奋的最大原因是，it work！效果优于传统机器学习 大量训练数据 CPU/GPU硬件资源的提升 Why is NLP hard？ 人类语言充满歧义 人类语言非常简练，省略了大量背景知识，not saying many thing The Pope’s baby steps on gays Deep NLP = Deep Learning + NLP近年来的研究进展 Levels：语音、词汇、语法、语义 Tools：词性标注、命名实体识别、句法/语义分析 Applications：机器翻译、情感分析、客服系统、问答系统 语义 Semantics 传统：Lambda calculus，手写大量规则 DL：每个短语、句子、逻辑表述都是向量 情感分析 传统：构建情感极性词典 QA 传统：大量逻辑规则 机器翻译 传统：在许多层级上进行尝试，试图找到一种世界通用的”国际语“作为翻译桥梁 DL：以Vector为翻译桥梁]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>CS224n</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime使用指南]]></title>
    <url>%2F20180412%2F17_sublime_using%2F</url>
    <content type="text"><![CDATA[个人Sublime使用记录 侧边显示文件结构 View-Side Bar-Show Side Bar File-Open Folder 导入了文件夹才会有文件夹的显示 安装Package Controlpython环境配置 安装SublimeRePL Preferences-Package Control 键入install packages 稍等片刻，键入SublimeRePL 等待安装即可 键位绑定 Preferences-Key Bindings123456789101112131415161718 &#123; "keys": ["f1"], "caption": "SublimeREPL: Python", "command": "run_existing_window_command", "args": &#123; "id": "repl_python", "file": "config/Python/Main.sublime-menu" &#125;&#125;,&#123; "keys": ["shift+enter"], "caption": "SublimeREPL: Python - RUN current file", "command": "run_existing_window_command", "args": &#123; "id": "repl_python_run", "file": "config/Python/Main.sublime-menu" &#125;&#125; markdown支持 安装SublimeRePL Preferences-Package Control 键入install packages 稍等片刻，键入Markdown Preview 等待安装即可 键位绑定 Preferences-Key Bindings12345678&#123; "keys": ["f2"], "command": "markdown_preview", "args": &#123; "target": "browser", "parser":"markdown" &#125;&#125; OneNote更友好的代码显示 方法很多，详见知乎 个人觉得最好的方法Sublime+SublimeHighlight 安装Sublime，好用的编辑器，不多说了 安装Package Control 安装SublimeHighlight Preferences-Package Control 键入Add Repository，用来添加插件安装源 地址栏输入https://github.com/n1k0/SublimeHighlight/tree/python3 Preferences-Package Control 键入install packages 稍等片刻，键入SublimeHighlight 等待安装即可 配置 Preference-Package Setting-Sublime Highlight-User Setting123456&#123; "theme": "monokai", "linenos": "inline", # 显示行号，不想显示设为false "noclasses": true, "fontface": "Menlo"&#125; 选中代码，右键Copy as HTML OneNote中新建1x1表格，复制进去即可 最后也可以修改表格底色 Python的Tab键换成四个空格 Preferences-setting 添加&quot;translate_tabs_to_spaces&quot;: true Python代码自动补全 参考：让你用sublime写出最完美的python代码—windows环境 连接远程服务器字体设置123&quot;font_face&quot;: &quot;Microsoft YaHei Mono&quot;,&quot;line_padding_bottom&quot;: 2,&quot;line_padding_top&quot;: 2, Microsoft YaHei Mono中文默认使用微软雅黑，英文默认使用Consolas，舒服 line_padding_bottom和line_padding_top设置行间距，可解决中英文没对齐问题]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Sublime</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法面试快问快答]]></title>
    <url>%2F20180402%2F16_offer_ML%2F</url>
    <content type="text"><![CDATA[见招拆招，算法面试套路~ 问题不保证全面，不保证有意义，仅记录我面过的，见过的，觉得可能能面的答案不保证100%正确，100%全面，能在面试官面前眉飞色舞地吹就行答案偏口语化，毕竟面试如有错误，或有补充，欢迎评论指出 安利个非常有用的算法基础教程【牛客网出品】直通BAT — 求职算法精品课，资源私聊（右下角DaoVoice or 文末评论） 机器学习基本概念 经验误差&泛化误差 学习器在训练集上的误差称为训练误差或经验误差，在新样本上的误差称为泛化误差 显然，我们希望得到泛化误差小的学习器 然而，我们事先并不知道新样本是什么样，实际能做的是努力使经验误差最小化，同时需要对过拟合进行一定处理 MSE、RMSE、MRE、MAE、MAPE MSE：均方误差 RMSE：均方根误差，针对异常值更加敏感；衡量预测值与真值之间的偏差，对误差取了平方，使得计算结果与较大值更相关，公式$RMSE=\sqrt{\frac{1}{n}\sum _{t=1}^n(|A_t-F_t|)^2}$ MRE：平均相对误差 MAE：平均绝对误差 MAPE：平均绝对百分比误差，不仅考虑了预测值与真实值的误差，还考虑了误差与真实值之间的比例，公式$MAPE=\frac{100}{n}\sum _{t=1}^n|\frac{A_t-F_t}{A_t}|$ other P、R、F1、ROC P：准确率/查准率，真正例(TP)占全部预测正例(TP+FP)的比例 R：召回率/查全率，真正例(TP)占全部正例(TP+TF)的比例 F1：准确率和召回率的调和平均 $F_1=\frac{2RP}{R+P}$ $F_\beta =\frac{1}{1+\beta ^2}(\frac{1}{P}+\frac{\beta ^2}{R})$ ROC：横轴假正例率，纵轴真正例率 ROC曲线的画法 对预测结果进行排序 阈值设置为最大值，此时所有样本均为负例，真正例率与假正例率均为零，表现为原点 逐渐降低阈值，依次使得每个样本预测为正例 如果下一个样本是真正例，对应y值加上1/n，否则x值加上1/n（假设当前坐标为(x, y)，如果该样本是真正例，则下一个点坐标为$(x, y+\frac{1}{n^+})$；如果该样本是假正例，则下一个点坐标为$(x+\frac{1}{n^+}, y)$） 最后阈值设置最小，使得所有样本预测为正例，此时对应坐标(1, 1) 防止过拟合的方法 获取更多数据：从数据源头获取、根据数据分布生成、数据增广 正则化：更小的参数值w意味着模型的复杂度更低，对训练数据的拟合刚刚好 Bagging、Boosting、Dropout 贝叶斯方法 混淆矩阵 预测正例P 预测反例N 正例T TP TN 反例F FP FN 常用的归一化方式 标准归一化 $z=\frac{x_i-\mu }{\delta }$ 当使用距离来度量相似性时，标准归一化表现更好 需要原始数据至少近似呈现正态分布 最大最小归一化 $z=\frac{x_i-min }{max-min}$ 缺点是新数据的加入可能导致max和min的变化 对方差非常小的属性可以增强其稳定性 维持稀疏矩阵中为0的条目 图像处理中，常将RGB图像转化为灰度图像后将其值限定在[0 255]的范围 线性比例变化法 softmax变化 为什么要归一化 不同特征之间往往具有不同的量纲和量纲单位，使得损失函数可能呈现出扁平状，此时的梯度下降过程是曲折的 提升模型的精度，量级相差太多的数运算会导致许多错误，让损失函数中的数据不要太大或者太小 梯度下降过程中，能更好的找到最小值 LR 什么是最小二乘法 基于均方误差最小化来进行模型求解的方法；试图找到一条直线，使所有样本到直线上的欧式距离之和最小 什么是LR 从线性模型出发，我们有$y=w^Tx+b$，就是使用x的线性组合去预测y，y也可以是关于y的单调可微函数，这是广义线性模型 对于一个二分类问题来说，需要将结果转换为0/1值，最容易想到的就是单位阶跃函数。很明显，这是不可微的 于是我们就找到了sigmoid函数，能在一定程度上近似单位阶跃函数 最后，LR就是用线性模型的预测结果去逼近真实标记的对数几率 sigmoid $y=\frac{1}{1+e^{-z}}$ 一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值 $y’=y(1-y)$ 极大似然估计与最小二乘 最小二乘法试图找到一条直线或者一个超平面，使得所有样本到该直线的欧氏距离最小 极大似然估计使模型对于此数据集中样本值的发生概率最大，也就是使模型能尽可能拟合现有数据集中现有的样本 LR极大似然估计计算 $P(y=1|x;w)=\sigma (wx)$ $P(y=0|x;w)=1-\sigma (wx)$ 取似然函数 $l(w)=\prod _{i=1}^mP(y_i|x_i;w)=\prod \sigma (wx_i)^{y_i}(1-\sigma (wx_i))^{1-y_i}$ $-L(x)=log l(w)=\sum _{i=1}^m(y_ilog\sigma (wx_i)+(1-y_i)log(1-\sigma (wx_i)))$ 问题转化为求L(x)最小值 $\frac{\partial L}{\partial (wx_i)}=\frac{\partial L}{\partial \sigma (wx_i)}\frac{\partial \sigma (wx_i)}{\partial (wx_i)}$ $=[-y_i\frac{1}{\sigma (wx_i)}-(1-y_i)\frac{-1}{1-\sigma (wx_i)}]\sigma (wx_i)(1-\sigma (wx_i))$ $-y_i(1-\sigma (wx_i))+(1-y_i)\sigma (wx_i)$ $\sigma (wx_i)-y_i$ 信息量、熵、交叉熵 信息量：事件发生概率越大，它所携带的信息量越小$l(x)=-logp(x)$ 熵：衡量的是事件发生的确定性，所有可能取值的信息量的期望，熵越大，变量的取值就越不确定$H(x)=-\sum _xP(x)logP(x)$ 交叉熵：衡量着两个分布之间的差异，两个随机分布间的距离度量 什么是最大熵原理 学习概率模型时，在所有可能的概率模型中，熵最大的模型是最好的模型 L1与L2的区别 TODU SVM 什么是SVM 支持向量机是一种二分类模型，它的基本思路是在特征空间中寻找间隔最大化的分割超平面 线性可分支持向量机：训练样本线性可分，硬间隔最大化 线性支持向量机：训练样本近似线性可分，软间隔最大化 非线性支持向量机：训练样本线性不可分，软间隔最大化+核技巧 为什么采用间隔最大化 当训练样本线性可分时，存在无穷多个分割超平面 利用间隔最大化可以找到最优的超平面，此时，解是唯一的，对未知样本的泛化能力也是最强的 什么是间隔 间隔分为函数间隔与几何间隔 函数间隔与几何间隔的关系是，几何间隔=函数间隔/w的模 函数间隔是$y_i (wx_i+b)$，其中$|wx+b|$相对地表示点x距离超平面的远近，符号是否一致就能表示分类是否正确，整个式子就能表示分类的正确性以及确信度 然后我们看到函数间隔是有一定问题的，我们保持超平面不变，只是等比例地改变w，b，此时函数间隔也会发生变化 因此引入几何间隔的概念，$y_i(\frac {w} {‖w‖}x_i+\frac {b}{‖w‖})$，将w，b同时除以w的模，使得间隔唯一确定下来 间隔最大化 公式TODU 首先，我们希望最大化几何间隔，约束条件是超平面(w, b)关于每个训练样本点的距离都至少是$\gamma $ 根据几何间隔与函数间隔的关系，可以写出第二个式子 其中，函数间隔的取值并不影响最优化问题的解，我们不失一般性地取$\hat{\gamma }=1$，同时注意到最大化$\frac {1} {‖w‖}$与最小化$\frac {1} {2}‖w‖^2$是等价的 核函数、核技巧 核函数：将输入从输入空间映射到特征空间中进行内积计算 核技巧：通过核函数，隐式地在高维特征空间中进行学习 为什么要使用核函数 样本在原始空间不可分时，需要将原始空间映射到一个高维的特征空间，使得样本在这个特征空间内线性可分 映射函数往往不好求，通过核函数可以不显式地定义映射函数 特征空间一般是高维的，甚至可能是无穷维 而在SVM中，只涉及向量之间的内积运算 什么是支持向量 训练数据集的样本点与分离超平面距离最近的样本点的实例 也就是$wx+b = ±1$上的点 SMO算法 在SVM中，会有很多变量需要进行最优化求解 SMO的基本思路就是选择两个变量，固定其他变量，针对这两个变量进行求解 这样不断将原问题分解为只有两个变量的子问题，并对子问题进行解析求解 直到所有的变量都满足KTT条件为止 第一个变量选取：最不满足KTT条件的样本点 第二个变量选取：与第一个变量间距最大 各种核函数 多项式核$K_Q(x_i,x_j)=(\zeta + \gamma x_i^Tx_j)^Q$ 高斯核函数$K(x_i,x_j)=exp(-\frac{\left | x_i-x_j \right |^2}{2\sigma ^2})$ $\sigma$很大，低维；$\sigma$很小，高维，可能过拟合 为什么也叫径向基核函数，因为高斯函数本身就是一个径向基函数，径向基函数是取值依赖于距离的函数 为什么RBF能映射到无穷维 泰勒展开 核函数的优缺点 线性核函数 优点：最简单，计算速度最快，更可解释 缺点：需要线性可分或近似线性可分 多项式核函数 优点：比线性核函数的限制少，当我们对实际问题有一定了解时，可能很好地认为限定Q 缺点：Q较大时，计算困难，可能导致核函数趋近于0或者无穷大；参数选择较多，有三个 高斯核函数 优点：能映射到无穷维，因此可以拟合复杂的非线性问题；高斯函数数值上在0-1之间，更好计算；参数更好调节 缺点：可解释性差；计算速度慢；过拟合 食用技巧 特征数m远大于样本数n，LR或线性核函数SVM 特征数m小于样本数n，高斯核函数SVM 样本数n非常大，此时高斯核函数SVM速度会很慢，因该引入更多特征 K-Means 什么是K-Means K-Means是一种聚类算法，基本思想是对于给定的类别数目k，首先给出初始划分，通过迭代改变样本和簇的隶属关系，使得每一次改变后的划分方案都比前一次好 K-Means具体做法 选择初始的k个类别中心 将每个样本标记为最近的类别 更新类别中心，将类别中心更新为该类别中所有样本的均值 重复前面两步，直到类别中心的变化小于某阈值或者迭代一定轮数 K-Means的优缺点 简单、快速 对高斯分布的数据集，效果较好 K需要预先定义 均值不可计算时无法使用 初值敏感 不适用于发现非凸或者大小差别很大的簇 对噪声和孤立点敏感 K值的确定 经验 又放回抽样，对不同的K值做两次聚类，计算相似性 计算平均轮廓系数 对不同的K值计算平方误差和（SSE），随着K的增大，SSE是肯定会降低的，找到那个开始降低不明显的点 初始化聚类中心 K-Means++ 先计算整体样本中心，然后从中心点出发，由近至远均匀采样 划分区域，区域中心未聚类中心 先用层次聚类初始聚类，再进行K-Means K-Means++算法 随机选取第一个聚类中心 计算每个点到最近聚类中心的距离D(x) 选择D(x)最大的点作为下一个聚类中心 重复上面步骤，直到得到k个聚类中心 决策树 什么是决策树 决策树是一种树形结构学习器 从根节点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子节点 如此递归地对实例进行测试并分配，直到达到叶节点 由决策树的根节点到叶节点的每一条路径就构建除了一条规则 决策树学习本质上是从训练集中归纳出一组分类规则 决策树的三个步骤 特征选择 决策树的生成 决策树的修剪 决策树终止条件 节点样本集合为空 节点样本属于同一类别 节点属性集合为空 熵、条件熵、信息增益、基尼系数 基尼系数$Gini(p) = - \sum _{k=1}^Kp_k(1-p_k) = 1 - \sum ^Kp_k^2$ 熵：随机变量的不确定性的度量$H(X) = -\sum _{i=1}^np_ilogp_i$ 信息增益：g(D,A) = H(D) - H(D|A)，H(D)表示对数据集D进行分类的不确定性；H(D|A)表示特征A给定的条件下对数据集D分类的不确定性；信息增益则表示，由于特征A而使得数据集D的分类不确定性减少的程度 ID3、C4.5、CART ID3：基于信息增益的大小来逐层确定分类特征，偏向于选择取值多的特征 C4.5：先从候选特征中找出信息增益高于平均水平的特征，再从中选择信息增益比最高的 CART：分类树用基尼系数最小化，回归树用平方误差最小化 ID3的具体过程 从跟节点开始，对节点计算所有可能的特征信息增益 选择信息增益最大的特征作为节点的特征，由该特征的不同取值建立子节点 再对子节点递归地调用以上方法，构建决策树 直到所有特征的信息增益均很小或没有特征可以选择为止 决策树怎么剪枝 极小化决策树整体损失函数 决策树的优缺点 树形，非线性，简单，易于理解 能处理数据缺失问题 能处理多分类问题 能同时处理连续型变量与离散型变量 缺点：容易过拟合，启发式 CART特点、剪枝、对缺失值的处理 每个节点采用二叉分裂，分裂准则采用基尼系数或者平方误差最小 剪枝：从生成算法产生的决策树底端开始不断剪枝，直到根节点，形成一个T0, T1, …, Tn的子序列 缺失值：训练的过程中保存替代特征，对于缺失数据，用替代特征进行划分 C4.5对缺失值的处理 划分点选择：未缺失样本的信息增益乘以为缺失样本的占比 怎么划分：让同一样本以不同的概率划入到不同的子节点中 分类与回归树的区别 分类树使用信息增益/信息增益比/基尼系数进行划分节点 回归树使用均方误差来划分节点 预剪枝与后剪枝 预剪枝：在决策树生成过程中，对每个节点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前节点标记为叶节点 先从训练集生成一颗完整的决策树，然后从底向上地对非叶节点进行考察，若将该节点对应地子树替换为叶节点能带来决策树泛化性能提升，则将该子树替换为叶节点 随机森林 什么是随机森林 随机森林是以决策树为基学习器构建Bagging集成 进一步在决策树的训练过程中引入了随机特征组合 具体地说，就是在决策树每次进行最优划分特征选择时，不考虑所有的特征，而只考虑随机的特征子空间或者随机特征组合 随机森林的优点 高效并行训练 决策树的所有优点 降低了过拟合的可能 可用评估特征的重要性，做特征选择 怎么自我验证 随机森林采用了bagging的方式，每次训练大约有1/3的数据可以用于做验证 对于每个样本xn，都有部分子决策树没有使用该样本进行训练，我们将这些子树拿出来就组成了$G_n^− (x_n)$，再求一下误差值，最终将所有的$G_n^− (x_n)$综合起来 特征重要度衡量 将OOB的特征值进行重排，对模型效果影响是否显著 集成学习 什么是集成学习 对于一个复杂的任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好 什么是Boosting Boosting就是从弱学习算法出发，反复学习，得到一系列弱学习器，然后组合这些弱学习器得到一个强学习器 什么是AdaBoost 先从初始训练集训练出一个基学习器，在根据基学习器的表现对训练样本分布进行调整，使得之前错的训练样本在后续受到更多关注，也就是提高那些被前一轮分类器错误分类样本的权值，而降低那些被正确分类样本的权值 最终采用加权多数表决进行综合 什么是Gradient_Boosting 通过迭代拟合损失函数的负梯度值，让损失函数持续下降 每次迭代先求得关于累加函数F(x)的负梯度(- gradient)，然后通过弱学习器f(x)去拟合该负梯度，然后将弱学习器f累加到F得到新的F 当损失函数是平方损失时，该负梯度值也就是残差，模型退化为回归提升模型 什么是Bagging 基于bootstrap sampling：从m样本中，有放回地取出m个样本 构建多个学习器，并集成 什么是XGBoost 一个GBDT大规模并行开源框架 GBDT是一种Boosting Boosting是… GBDT与提升树的区别 提升树拟合的是残差，损失函数是均方误差；GBDT拟合的是负梯度值 GBDT中引入了学习率 GBDT如何转换为分类问题 二分类：比较最终的概率大小，区分属于正类还是负类 多分类：生成k棵回归数，每棵树的叶节点表示某一类样本的得分，样本最终对各类的概率由softmax对每个得分归一化处理得到 XGBoost与GBDT的区别 传统的GBDT以CART树为基学习器，XGBOOST还支持线性分类器，这时候的XGBOOST就相当于加了正则项的逻辑回归或者线性回归 XGBOOST在代价函数中加入了正则项，用于控制模型的复杂度；L1可以控制叶节点的个数，L2可以控制叶节点上的样本数目 传统GBDT在优化的时候只用到了一阶导数，XGBOOST则对代价函数进行二阶泰勒展开，同时利用一阶和二阶导信息计算 列抽样：XGBOOST借鉴了随机森林的做法，对特征抽样再拟合，不仅防止过拟合，还能减少计算 并行结算：XGBOOST在特征粒度上开多个线程同时计算它们各自的最佳信息增益 ARIMA 什么是ARIMA模型 AR是使用当前观察点以及若干延迟时期观察点的依赖关系进行建模 MA是使用当前观察点以及若干延迟时期观察点在移动平均模型上的残差的依赖关系进行建模 I表示对数据地差分，使得不平稳地序列变得平稳 稳定的标准 恒定的平均数 恒定地方差 不随时间变化地自协方差 平稳的定义 常数均值 自协方差与自相关系数只依赖于时间地平移长度而与时间地起止点无关 平稳的序列通常具有短期相关性 用自相关系数来描述就是随着延迟期k的增加，平稳序列的自相关系数会很快衰减向零 如何判断是否平稳 在自相关图（PAC）上，随着延迟期数k的增加，自相关系数很快衰减向零，且之后始终控制在2倍标准差范围内 为什么引入2倍标准差呢？由于样本的随机性，很难确定是否真正截尾（最初的d阶明显超过2倍标准差范围，而后几乎95%的（偏）自相关系数都落在2倍标准差范围以内，则d阶截尾） ARIMA建模的一般过程 平稳性检验（DF检验） 白噪声检验 定阶 偏自相关系数定p 自相关系数定q 参数估计 模型验证 模型的显著性检验：残差为白噪声，好的拟合模型能够提取观测序列中几乎所有样本的相关信息 参数的显著性检验：每一个未知参数显著非零 模型优化，AIC、SBS越小越好 自协方差&自相关系数 方差$\sigma _t^2=D(X_t)=E(X_t-\mu _t)^2$ 自协方差$\gamma (t,s)=E(X_t-\mu _t)E(X_s-\mu _s)$ 自相关系数$ACF=\frac{\gamma (t,s)}{\sqrt{D(X_t)D(X_s)}}$ 梯度下降 梯度下降是什么 梯度下降法是最小化目标函数$J(\theta )$的一种方法 梯度下降法利用目标函数关于参数的梯度$\bigtriangledown _\theta J(\theta )$的反方向更新参数。 学习率$\eta$决定达到最小值或者局部最小值过程中所采用的步长大小 对于凸误差函数，批量梯度下降法能够保证收敛到全局最小值，对于非凸函数，则收敛到一个局部最小值 BGD、SGD、小批量梯度下降对比 BGD $\theta = \theta - \eta \bigtriangledown _\theta J(\theta )$ 在整个训练集上计算损失函数关于参数θ的梯度 计算速度慢、内存需求高 不能在线更新模型 对于非凸损失函数，容易陷入局部最优 SGD $\theta = \theta - \eta \bigtriangledown _\theta J(\theta ;x^i;y^i)$ 批量梯度下降会对相似样本计算梯度，造成冗余；而SGD从一定程度上消除冗余 训练速度快 支持在线学习 波动性使得SGD可以跳出局部最优，但也使得收敛变得复杂 小批量梯度下降 $\theta = \theta - \eta \bigtriangledown _\theta J(\theta ;x^{i:i+n};y^{i:i+n})$ 减少参数更新的方差，这样可以得到更加稳定的收敛结果 可以利用最新的深度学习库中高度优化的矩阵优化方法，高效地求解每个小批量数据的梯度 如果学习率很小或者梯度随着x变化很小，SGD与批梯度下降法具有相同的收敛行为 改进得梯度下降 动量法(Momentum)在梯度方向上增加一个分量，这个分量与历史步长有关 NAG给动量项预知得能力 Adagrad自适应学习率 Adadelta克服Adagrad学习率单调递减问题 RMSpropAdadelta得一个特例 Adam 食用技巧 如果输入数据是稀疏的，选择任一自适应学习率算法可能会得到最好的结果。选用这类算法的另一个好处是无需调整学习率，选用默认值就可能达到最好的结果 优化后期由于梯度变得越来越稀疏，偏差校正能够帮助Adam微弱地胜过RMSprop 如果你关心的是快速收敛和训练一个深层的或者复杂的神经网络，你应该选择一个自适应学习率的方法 优化SGD 大多数情况下希望避免模型中以一定意义的顺序提供训练数据，通过洗牌避免；另一方面，有些情况下需要逐步解决问题 批量归一化 Early Stopping 梯度噪音 LSTM 什么是RNN RNN对序列的每一个元素都执行相同的任务，输出依赖于先前的计算 普通神经网络，基于data0预测result0，data1预测result1 当我们的data0跟data1是相互关联的时候，普通的神经网络不能了解这种关联 而RNN就是让神经网络具备记住之前发生事情的能力 当data0预测result0的时候形成记忆state0，然后在data1预测result1的时候将之前的记忆state0调用过来 RNN公式 $o_t=g(Vs_t)$ $s_t=f(Ux_t+Ws_{t-1})$ 解释梯度消失以及LSTM怎么缓解 在传统的RNN中，单元状态$s_t$可以表示为，$s_t=f(Ux_t+W_{t-1})$，根据求导的链式法则，可以看出，$s_t$对U、W的偏导跟$s_{t-1}$ 有关，最后会形成一个与W有关的累乘形式 这种累乘的求导形式正是导致梯度问题的关键，简单的说，如果这个W小于1，最后的误差就几乎消失，如果这个W大于1，不断累乘，误差可能变成一个无穷大的数 在LSTM中，由于门控单元的引入，在反向传播中，先会经过一个加法操作，然后再与遗忘门$f_t$相乘，累乘形式中不再是固定的W，而是变化的遗忘门$f_t$，这能在一定程度上缓解梯度消失 进一步看，这个遗忘门是一个sigmoid函数，最终的累乘形式中包含$tanh′(x)\sigma(y)$的形式，而这个乘积本身是一个非0即1的值 简单地说，原始RNN的隐藏层只有一个状态，它对于短期的输入非常敏感，LSTM就是再增加一个状态，用它来保存长期的状态 不同反向传播方式 全反向传播 误差会一直传递到初始时刻 计算开销大 梯度消失的存在，使得进一步反向传播不再重要 截断反向传播 真截断：每个误差反向传播n steps Tensorflow-style：切成n个子序列，n个误差被反向传播了n steps 结论：随着BPTT steps的增加，Tensorflow-style逐渐占据优势 LSTM的门 遗忘门决定了上一时刻的单元状态$c_{t−1}$有多少保留到当前时刻$c_t$ 输入门决定了当前时刻网络的输入$x_t$有多少保存到单元状态$c_t$ 输出门决定了单元状态$c_t$有多少输出到LSTM的当前输出值$h_t$ 遗忘门：$f_t=W_f[h_{t-1},x_t]+b_f$ 输入门：$i_t=W_i[h_{t-1},x_t]+b_i$ 输出门：$o_t=W_o[h_{t-1},x_t]+b_o$ 本次输入的单元状态：$c’_t=tanh(W_c[h_{t-1},x_t]+b_c)$ 本次输出的单元状态：$c_t=f_t\circ c_{t-1}+i_t \circ c’_t$ 最终输出：$h_t=o_t \circ tanh(c_t)$ sigmoid、tanh、Relu sigmoid 梯度饱和问题：sigmoid在激活值接近于0或者1时，梯度接近于0，反向传播过程中容易出现梯度弥散 sigmoid函数输出不是以0为中心 tanh 同样存在梯度饱和问题 函数输出以0为中心 Relu(Rectified Linear Unit，修正线性单元) 减轻了梯度弥散问题 Relu会使部分神经元的输出为0，造成网络的稀疏性，缓解过拟合 计算速度快 RNN梯度问题公式 TODU GRU Gated Recurrent Unit 更新门：$z_t=\sigma (W_z[h_{t-1},x_t]+b_z)$ 重置门：$r_t=\sigma (W_r[h_{t-1},x_t]+b_r)$ 候选隐藏层：$h’_t=tanh(W[r_t \circ h_{t-1}, x_t]+b)$ 输出：$h_t=(1-z_t \circ h_{t-1}+z_t \circ h’_t)$ 更新门：决定了先前记忆信息的保留程度 重置门：决定了新的输入与前一时刻记忆的组合方式 当$r_t=1$，$z_t=0$。这就是个普通的RNN CNN 什么是CNN 卷积神经网络里的“卷积”，代表的是神经网络不再是对每个像素的输入信息做处理了,而是图片上每一小块像素区域进行处理, 这种做法加强了图片信息的连续性。使得神经网络能看到图形, 而非一个点。 卷积神经网络与传统全连接网络的区别在于1. 神经元间的连接是非全连接的，2. 同一层中某些神经元之间的连接的权重是共享的 什么是pooling 在每一次进行多步的卷积时, 神经层可能会无意地丢失一些信息 pooling就是为了解决这个问题 在进行卷积时不压缩长宽，也就是步长设置为1，这样可以尽量保留更多信息，压缩的工作就交给pooling层去做 pooling分为Max pooling和Average pooling，前者取最大值代表一小块区域，后者取平均值 Relu的优势 速度快，和sigmoid函数需要计算指数和倒数相比，relu函数其实就是一个max(0,x)，计算代价小很多 减轻梯度消失问题 稀疏性，relu函数在输入小于0时是完全不激活的，因此可以获得一个更低的激活率 TODU TODU NLP 语言模型 前面i个词出现的条件下，第i+1个词出现的概率 $P(x_i, …, x_m)=\prod _{i=1}^mP(w_i|w_i, …, w_{i-1})$ Word2Vec、Embedding Word2Vec是从大量文本语料中无监督的方式学习语义知识的一种模型 Embedding其实就是一个映射，将单词从原先所属的空间映射到新的多维空间中，也就是把原先词所在空间嵌入到一个新的空间中去 CBOW、Skip-Gram CBOW：给定上下文，来预测input word Skip-Gram：给定input word，来预测上下文 Skip-Gram_in_Word2Vec 在skip_window*2的窗口范围内，随机选取num_skips个词，产生一系列（input_word, output_word）对 (1, 10000)的向量与(10000, 300)的向量直接相乘将消耗大量的资源，转换为取出矩阵中对应向量值为1的索引行 改进： 词组 高频词抽样处理，抽样率根据出现频次计算 负采样，每次训练一个样本仅更新一小部分的权重 对应输出为1以及少数输出为0的神经元 negative words的选取，出现频次越高，越容易被选取 实际代码中有一种unigram table，一亿维，单词索引重复出现，负采样概率越高，出现次数越多 TODU TODU]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>ML</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解stateful LSTM]]></title>
    <url>%2F20180116%2F15_understanding_stateful_LSTM%2F</url>
    <content type="text"><![CDATA[原文Understanding Stateful LSTM Recurrent Neural Networks in Python with Keras 任务描述：学习字母表 【1】Naive LSTM for Learning One-Char to One-Char Mapping 使用t时刻序列值，预测t+1时刻序列值 输入维度1，输入用one hot编码 效果不好，原因： LSTM没有可以考虑的上下文 每批训练，Keras默认重置网络状态 本质上是将LSTM单元用作多层感知机，是对LSTM的误用 【2】Naive LSTM for a Three-Char Feature Window to One-Char Mapping 使用t-n, t-n+1, …, t时刻序列值为特征，预测t+1时刻序列值 性能小幅提升，但同样不好 本质上仍是将LSTM单元用作多层感知机，只不过通过window method来提供上下文，是对LSTM的误用 事实上，序列特征是具有time steps的一个特征，而不是one time step的多个特征 【3】Naive LSTM for a Three-Char Time Step Window to One-Char Mapping 使用t-n, t-n+1, …, t时刻序列值为time steps特征，预测t+1时刻序列值 正确率100%，可以很好的学习到字母表 但只能通过前n个序列值预测第n+1个序列值，而不是完整的学习了整张字母表 事实上，通过一个足够大的多层感知机也似乎能完成 【4】LSTM State Within A Batch 使用整个序列训练模型，输入t时刻序列值，预测t+1时刻序列值 LSTM是有状态的，但在每批训练之后，Keras会默认重置。这意味着，如果我们使用一个足够大的batch，一次训练所有数据，则LSTM会很好的考虑上下文信息 正确率100%，可以输入任意字母预测下一个字母 问题在于，每批训练都要给网络喂全量数据 【5】Stateful LSTM for a One-Char to One-Char Mapping 使用整个序列训练模型，输入t时刻序列值，预测t+1时刻序列值 Ideally, we want to expose the network to the entire sequence and let it learn the inter-dependencies, rather than us define those dependencies explicitly in the framing of the problem. 上述通过stateful LSTM来实现，这才是LSTM的正确用法 手动训练每一期（epoch），每期分为多批，每批训练状态会被记录并传递到下一批，直到本期训练完成后重置状态 正确率理论100%（增加epoch可提高正确率） 冷启动问题，网络的第一个输入不能被正确预测 类似于【3】，但不是人为确定time step，而是由网络自主学习 【6】LSTM with Variable-Length Input to One-Char Output 使用t时刻前可变序列值，预测t+1时刻序列值 定义输入最大time steps，不够最大长度的在前面补0 效果一般，但已经能通过任意长度的序列预测下一刻序列值 本质上就是【3】，输入改为可变长度]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>DL</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【译】不同的截断反向传播]]></title>
    <url>%2F20171221%2F14_styles_of_truncated_backpropagation%2F</url>
    <content type="text"><![CDATA[本文GitHub地址博客地址原文Styles of Truncated Backpropagation翻译带个人理解，建议啃原文 笔者在之前的博文Recurrent Neural Networks in Tensorflow中观察到，TensorFlow的截断反向传播方式与“误差最多反向传播n steps”不同。笔者将在这篇博文中基于TensorFlow实现不同的截断反向传播算法，并研究哪种方法更好。 结论是： 一个实现得很好、均匀分布的截断反向传播算法与全反向传播（full backpropagation）算法在运行速度上相近，而全反向传播算法在性能上稍微好一点。 初步实验表明，n-step Tensorflow-style 反向传播（with num_step=n）并不能有效地反向传播整个n steps误差。因此，如果使用Tensorflow-style 截断反向传播并且需要捕捉n-step依赖关系，则可以使用明显高于n的num_step以便于有效地将误差反向传播所需的n steps。 Differences in styles of truncated backpropagation假设要训练一个RNN，训练集为长度10,000的序列。如果我们使用非截断反向传播，那么整个序列会一次性地喂给网络，在时刻10,000的误差会一直传递到时刻1。这会导致两个问题： 误差反向传播这么多步的计算开销大 由于梯度消失，反向传播误差逐层变小，使得进一步的反向传播不再重要 可以使用“截断”反向传播解决这个问题，Ilya Sutskever博士这篇文章的2.8.6节有一个对截断反向传播很好的描述： “[Truncated backpropagation] processes the sequence one timestep at a time, and every k1 timesteps, it runs BPTT for k2 timesteps…” Tensorflow-style反向传播使用k1=k2(=num_steps)（详情请参阅Tensorflow Api）。本文提出的问题是：k1=1能否得到一个更好的结果。本文认为，“真”截断反向传播是：每次反向传播k2 steps都是传播了整个k2 steps。 举个例子解释这两种方法的不同。序列长度为49，反向传播截断为7 steps。相同的是，每个误差都会反向传播7 steps。但是，对于Tensorflow-style截断反向传播，序列会被切分成长度为7的7个子序列，并且只有7个误差被反向传播了7 steps。而对于“真”截断反向传播而言，42个误差能被反向传播7 steps就应该42个都反向传播7 steps。这就产生了不同，因为使用7-steps与1-steps更新权重明显不同。 为了可视化差异，下图表示的是序列长度为6，误差反向传播3 steps： 下图是Tensorflow-style截断反向传播在同一序列上的情况： 实验设计为了比较两种算法的性能，笔者实现了一个“真”截断反向传播算法，并与vanilla-RNN比较结果。vanilla-RNN是笔者在先前的博文Recurrent Neural Networks in Tensorflow I中使用的模型。不同的是，先前的网络在toy数据集上学习简单模式非常快，而本次提升了任务和模型的复杂性。这次任务是对ptb数据集进行语言建模，在基本的RNN模型中添加了一个embedding层和dropout层用以匹配任务的复杂性。 实验比较了每个算法20 epochs训练后验证集上的最佳性能，使用的是Adam Optimizer（初步实验它比其他Optimizer好），学习率设置为0.003，0.001和0.0003。 5-step truncated backpropagation True, sequences of length 20 TF-style 10-step truncated backpropagation True, sequences of length 30 TF-style 20-step truncated backpropagation True, sequences of length 40 TF-style 40-step truncated backpropagation TF-style 代码Imports and data generators12345678910111213import numpy as npimport tensorflow as tf%matplotlib inlineimport matplotlib.pyplot as pltfrom tensorflow.models.rnn.ptb import reader#data from http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgzraw_data = reader.ptb_raw_data('ptb_data')train_data, val_data, test_data, num_classes = raw_datadef gen_epochs(n, num_steps, batch_size): for i in range(n): yield reader.ptb_iterator(train_data, batch_size, num_steps) Model123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152def build_graph(num_steps, bptt_steps = 4, batch_size = 200, num_classes = num_classes, state_size = 4, embed_size = 50, learning_rate = 0.01): """ Builds graph for a simple RNN Notable parameters: num_steps: sequence length / steps for TF-style truncated backprop bptt_steps: number of steps for true truncated backprop """ g = tf.get_default_graph() # placeholders x = tf.placeholder(tf.int32, [batch_size, None], name='input_placeholder') y = tf.placeholder(tf.int32, [batch_size, None], name='labels_placeholder') default_init_state = tf.zeros([batch_size, state_size]) init_state = tf.placeholder_with_default(default_init_state, [batch_size, state_size], name='state_placeholder') dropout = tf.placeholder(tf.float32, [], name='dropout_placeholder') x_one_hot = tf.one_hot(x, num_classes) x_as_list = [tf.squeeze(i, squeeze_dims=[1]) for i in tf.split(1, num_steps, x_one_hot)] with tf.variable_scope('embeddings'): embeddings = tf.get_variable('embedding_matrix', [num_classes, embed_size]) def embedding_lookup(one_hot_input): with tf.variable_scope('embeddings', reuse=True): embeddings = tf.get_variable('embedding_matrix', [num_classes, embed_size]) embeddings = tf.identity(embeddings) g.add_to_collection('embeddings', embeddings) return tf.matmul(one_hot_input, embeddings) rnn_inputs = [embedding_lookup(i) for i in x_as_list] #apply dropout to inputs rnn_inputs = [tf.nn.dropout(x, dropout) for x in rnn_inputs] # rnn_cells with tf.variable_scope('rnn_cell'): W = tf.get_variable('W', [embed_size + state_size, state_size]) b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0)) def rnn_cell(rnn_input, state): with tf.variable_scope('rnn_cell', reuse=True): W = tf.get_variable('W', [embed_size + state_size, state_size]) W = tf.identity(W) g.add_to_collection('Ws', W) b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0)) b = tf.identity(b) g.add_to_collection('bs', b) return tf.tanh(tf.matmul(tf.concat(1, [rnn_input, state]), W) + b) state = init_state rnn_outputs = [] for rnn_input in rnn_inputs: state = rnn_cell(rnn_input, state) rnn_outputs.append(state) #apply dropout to outputs rnn_outputs = [tf.nn.dropout(x, dropout) for x in rnn_outputs] final_state = rnn_outputs[-1] #logits and predictions with tf.variable_scope('softmax'): W = tf.get_variable('W_softmax', [state_size, num_classes]) b = tf.get_variable('b_softmax', [num_classes], initializer=tf.constant_initializer(0.0)) logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs] predictions = [tf.nn.softmax(logit) for logit in logits] #losses y_as_list = [tf.squeeze(i, squeeze_dims=[1]) for i in tf.split(1, num_steps, y)] losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logit,label) \ for logit, label in zip(logits, y_as_list)] total_loss = tf.reduce_mean(losses) """ Implementation of true truncated backprop using TF's high-level gradients function. Because I add gradient-ops for each error, this are a number of duplicate operations, making this a slow implementation. It would be considerably more effort to write an efficient implementation, however, so for testing purposes, it's OK that this goes slow. An efficient implementation would still require all of the same operations as the full backpropagation through time of errors in a sequence, and so any advantage would not come from speed, but from having a better distribution of backpropagated errors. """ embed_by_step = g.get_collection('embeddings') Ws_by_step = g.get_collection('Ws') bs_by_step = g.get_collection('bs') # Collect gradients for each step in a list embed_grads = [] W_grads = [] b_grads = [] # Keeping track of vanishing gradients for my own curiousity vanishing_grad_list = [] # Loop through the errors, and backpropagate them to the relevant nodes for i in range(num_steps): start = max(0,i+1-bptt_steps) stop = i+1 grad_list = tf.gradients(losses[i], embed_by_step[start:stop] +\ Ws_by_step[start:stop] +\ bs_by_step[start:stop]) embed_grads += grad_list[0 : stop - start] W_grads += grad_list[stop - start : 2 * (stop - start)] b_grads += grad_list[2 * (stop - start) : ] if i &gt;= bptt_steps: vanishing_grad_list.append(grad_list[stop - start : 2 * (stop - start)]) grad_embed = tf.add_n(embed_grads) / (batch_size * bptt_steps) grad_W = tf.add_n(W_grads) / (batch_size * bptt_steps) grad_b = tf.add_n(b_grads) / (batch_size * bptt_steps) """ Training steps """ opt = tf.train.AdamOptimizer(learning_rate) grads_and_vars_tf_style = opt.compute_gradients(total_loss, tf.trainable_variables()) grads_and_vars_true_bptt = \ [(grad_embed, tf.trainable_variables()[0]), (grad_W, tf.trainable_variables()[1]), (grad_b, tf.trainable_variables()[2])] + \ opt.compute_gradients(total_loss, tf.trainable_variables()[3:]) train_tf_style = opt.apply_gradients(grads_and_vars_tf_style) train_true_bptt = opt.apply_gradients(grads_and_vars_true_bptt) return dict( train_tf_style = train_tf_style, train_true_bptt = train_true_bptt, gvs_tf_style = grads_and_vars_tf_style, gvs_true_bptt = grads_and_vars_true_bptt, gvs_gradient_check = opt.compute_gradients(losses[-1], tf.trainable_variables()), loss = total_loss, final_state = final_state, x=x, y=y, init_state=init_state, dropout=dropout, vanishing_grads=vanishing_grad_list ) Some quick tests速度测试不出所料，由于执行了重复操作，实现的真BPTT速度很慢。一个有效的实现运行速度将与全反向传播大致相同。 123456reset_graph()g = build_graph(num_steps = 40, bptt_steps = 20)sess = tf.InteractiveSession()sess.run(tf.initialize_all_variables())X, Y = next(reader.ptb_iterator(train_data, batch_size=200, num_steps=40)) 12%%timeitgvs_bptt = sess.run(g['gvs_true_bptt'], feed_dict=&#123;g['x']:X, g['y']:Y, g['dropout']: 1&#125;) 10 loops, best of 3: 173 ms per loop 12%%timeitgvs_tf = sess.run(g['gvs_tf_style'], feed_dict=&#123;g['x']:X, g['y']:Y, g['dropout']: 1&#125;) 10 loops, best of 3: 80.2 ms per loop 梯度消失演示为了演示梯度消失问题，收集以下信息。如你所见，梯度很快就会消失，每一步都会减少3-4倍。 123456789101112vanishing_grads, gvs = sess.run([g['vanishing_grads'], g['gvs_true_bptt']], feed_dict=&#123;g['x']:X, g['y']:Y, g['dropout']: 1&#125;)vanishing_grads = np.array(vanishing_grads)weights = gvs[1][1]# sum all the grads from each loss nodevanishing_grads = np.sum(vanishing_grads, axis=0)# now calculate the l1 norm at each bptt stepvanishing_grads = np.sum(np.sum(np.abs(vanishing_grads),axis=1),axis=1)vanishing_grads array([ 5.28676978e-08, 1.51207473e-07, 4.04591049e-07, 1.55859300e-06, 5.00411124e-06, 1.32292716e-05, 3.94736344e-05, 1.17605050e-04, 3.37805774e-04, 1.01710076e-03, 2.74375151e-03, 8.92040879e-03, 2.23708227e-02, 7.23497868e-02, 2.45202959e-01, 7.39126682e-01, 2.19093657e+00, 6.16793633e+00, 2.27248211e+01, 9.78200531e+01], dtype=float32) 12for i in range(len(vanishing_grads) - 1): print(vanishing_grads[i+1] / vanishing_grads[i]) 2.86011 2.67573 3.85227 3.21066 2.64368 2.98381 2.97933 2.87237 3.0109 2.69762 3.25117 2.50782 3.23411 3.38913 3.01435 2.96422 2.81521 3.68435 4.30455 1plt.plot(vanishing_grads) Quick accuracy test一个完整检查，以确保真截断反向传播算法运行正确。 123456789101112131415161718# first test using bptt_steps &gt;= num_stepsreset_graph()g = build_graph(num_steps = 7, bptt_steps = 7)X, Y = next(reader.ptb_iterator(train_data, batch_size=200, num_steps=7))with tf.Session() as sess: sess.run(tf.initialize_all_variables()) gvs_bptt, gvs_tf =\ sess.run([g['gvs_true_bptt'],g['gvs_tf_style']], feed_dict=&#123;g['x']:X, g['y']:Y, g['dropout']: 0.8&#125;)# assert embedding gradients are the sameassert(np.max(gvs_bptt[0][0] - gvs_tf[0][0]) &lt; 1e-4)# assert weight gradients are the sameassert(np.max(gvs_bptt[1][0] - gvs_tf[1][0]) &lt; 1e-4)# assert bias gradients are the sameassert(np.max(gvs_bptt[2][0] - gvs_tf[2][0]) &lt; 1e-4) 实验123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566"""Train the network"""def train_network(num_epochs, num_steps, use_true_bptt, batch_size = 200, bptt_steps = 7, state_size = 4, learning_rate = 0.01, dropout = 0.8, verbose = True): reset_graph() tf.set_random_seed(1234) g = build_graph(num_steps = num_steps, bptt_steps = bptt_steps, state_size = state_size, batch_size = batch_size, learning_rate = learning_rate) if use_true_bptt: train_step = g['train_true_bptt'] else: train_step = g['train_tf_style'] with tf.Session() as sess: sess.run(tf.initialize_all_variables()) training_losses = [] val_losses = [] for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps, batch_size)): training_loss = 0 steps = 0 training_state = np.zeros((batch_size, state_size)) for X, Y in epoch: steps += 1 training_loss_, training_state, _ = sess.run([g['loss'], g['final_state'], train_step], feed_dict=&#123;g['x']: X, g['y']: Y, g['dropout']: dropout, g['init_state']: training_state&#125;) training_loss += training_loss_ if verbose: print("Average training loss for Epoch", idx, ":", training_loss/steps) training_losses.append(training_loss/steps) val_loss = 0 steps = 0 training_state = np.zeros((batch_size, state_size)) for X,Y in reader.ptb_iterator(val_data, batch_size, num_steps): steps += 1 val_loss_, training_state = sess.run([g['loss'], g['final_state']], feed_dict=&#123;g['x']: X, g['y']: Y, g['dropout']: 1, g['init_state']: training_state&#125;) val_loss += val_loss_ if verbose: print("Average validation loss for Epoch", idx, ":", val_loss/steps) print("***") val_losses.append(val_loss/steps) return training_losses, val_losses 结果1234567891011121314151617# Procedure to collect results# Note: this takes a few hours to runbptt_steps = [(5,20), (10,30), (20,40), (40,40)]lrs = [0.003, 0.001, 0.0003]for bptt_step, lr in ((x, y) for x in bptt_steps for y in lrs): _, val_losses = \ train_network(20, bptt_step[0], use_true_bptt=False, state_size=100, batch_size=32, learning_rate=lr, verbose=False) print("** TF STYLE **", bptt_step, lr) print(np.min(val_losses)) if bptt_step[0] != 0: _, val_losses = \ train_network(20, bptt_step[1], use_true_bptt=True, bptt_steps= bptt_step[0], state_size=100, batch_size=32, learning_rate=lr, verbose=False) print("** TRUE STYLE **", bptt_step, lr) print(np.min(val_losses)) Minimum validation loss achieved in 20 epochs: BPTT Steps 5 Learning Rate 0.003 0.001 0.0003 True (20-seq) 5.12 5.01 5.09 TF Style 5.21 5.04 5.04 BPTT Steps 10 Learning Rate 0.003 0.001 0.0003 True (30-seq) 5.07 5.00 5.12 TF Style 5.15 5.03 5.05 BPTT Steps 20 Learning Rate 0.003 0.001 0.0003 True (40-seq) 5.05 5.00 5.15 TF Style 5.11 4.99 5.08 BPTT Steps 40 Learning Rate 0.003 0.001 0.0003 TF Style 5.05 4.99 5.15 Discussion如你所见，当以相同的steps截断误差时，“真”截断反向传播算法似乎比Tensorflow-style好。但是，随着BPTT steps逐渐增加，这种优势逐渐减弱，当Tensorflow-style截断反向传播steps为序列长度时，这种优势便消失了，甚至反过来。 所以结论是： 一个实现得很好、均匀分布的截断反向传播算法与全反向传播（full backpropagation）算法在运行速度上相近，而全反向传播算法在性能上稍微好一点。 初步实验表明，n-step Tensorflow-style 反向传播（with num_step=n）并不能有效地反向传播整个n steps误差。因此，如果使用Tensorflow-style 截断反向传播并且需要捕捉n-step依赖关系，则可以使用明显高于n的num_step以便于有效地将误差反向传播所需地n steps。 Edit: 写完这篇博文之后，才发现关于不同的截断反向传播已经在 Williams and Zipser (1992), Gradient-Based Learning Algorithms for Recurrent Networks and Their Computation Complexity这篇论文中讨论。作者将本文中提到的“真”反向传播定义为“截断反向传播”，表示为：BPTT(n)/BPTT(n, 1)；而Tensorflow-style截断反向传播定义为“epochwise 截断反向传播”，表示为：BPTT(n, n)。同时允许“semi-epochwise”截断BPTT，which would do a backward pass more often than once per sequence, but less often than all possible times (i.e., in Ilya Sutskever’s language used above, this would be BPTT(k2, k1), where 1 &lt; k1 &lt; k2).【译者注：本人才疏学浅未理解】 在 Williams and Peng (1990), An Efficien Gradient-Based Algorithm for On-Line Training of Recurrent Network Trajectories中，作者进行了类似本文的实验，并得出与本文类似的结论。Williams Peng写到“The results of these experiments have been that the success rate of BPTT(2h; h) is essentially identical to that of BPTT(h)”，也就是说，他比较了“真”截断h-steps反向传播与BPTT(2n, n)(这与截断2n-steps Tensorflow-style反向传播相似)，最终发现它们表现相近。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>DL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Debug Myself]]></title>
    <url>%2F20171023%2F13_debug%2F</url>
    <content type="text"><![CDATA[记录个人编程之路上遇到的问题以及解决方案 Keras 【2017.10.26】 ImportError: Failed to import pydot. You must install pydot and graphviz for pydotprint to work. 参考链接keras可视化遇到pydot&amp;graphviz无法导入问题stackoverflow Keras的Model visualization可以很方便可视化网络 123# Keras-2.0.8from keras.utils import plot_modelplot_model(model, to_file='model.png') 这个报错十分具有误导性…即使执行了pip install pydot；pip install pydot-ng；pip install graphviz还是有这个报错。报错的原因其实不在于pydot，跟python包没有关系，而是因为graphviz需要安装二进制执行文件（跟imagick类似），所以还需要去官网下一个graphviz安装包安装。双击运行之后一路next，最后将C:\Program Files (x86)\Graphviz2.38\bin加入系统环境变量。 12pip install pydotpip install pydot-ng # Keras 2.0.6之后只需安装pydot-ng 重启python即可 Ubuntu下解决方案conda install graphviz 【2018.10.11】设置GPU内存占比 使用Tensorflow或Keras时对GPU内存限制 TensorFlow 【2017.10.27】 Windows安装tensorflow-gpu 先安装cuda_8.0.44_win10-exe 解压cudnn-8.0-windows10-x64-v6.0.zip，并将三个文件复制到C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0中的相应位置 最后pip install --ignore-installed --upgrade tensorflow-gpu安装TensorFlow 直接在官网下的是cuda v9.0，目前tensorflow暂不支持！ 参考：TensorFlow安装方法二【GPU环境配置部分】（Windows10 64位 cpu and gpu） 【2017.12.13】 ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory 问题出在不能正确找到CUDA 在CUDA已经安装的前提下，在.bashrc文件中增加 1export LD_LIBRARY_PATH=/usr/local/cuda/lib64/ 如果需要在Pycharm中进行远程，则在run configuration中增加cuda lib的环境变量 【2018.05.11】 升级Tensorflow tensorflow升级到1.8之后，cuda需要升级到9.0 下载cuda_9.0.176_win10.exe以及cudnn-9.0-windows10-x64-v7.1.zip 自定义安装cuda_9.0.176_win10.exe，只安装CUDA 解压cudnn-9.0-windows10-x64-v7.1.zip，并将三个文件复制到C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0中的相应位置 在系统环境变量中删除之前版本的CUDA nvcc -V验证版本 目前tensorflow最新版本1.8.0只支持到CUDA9.0，如果想使用CUDA9.1，可以使用大神预编译好的版本，GitHUB地址。 Pycharm 【2017.12.13】 matplotlib显示远程服务器上图片 参考链接从零开始：使用PyCharm和SSH搭建远程TensorFlow开发环境Python plotting on remote server using PyCharmPycharm远程调用Centos GUI程序,显示在windows上matplotlib绘图错误：TclError: no display name and no $DISPLA emmmm，进入正题，我误打误撞的解决方案。MobaXterm + pycharm 使用MobaXterm登陆服务器 echo $DISPLAY查看MobaXterm转发显示的number，如localhost:10.0 在pycharm的run configuration中增加DISPLAY的环境变量 XGBOOST 【2018.05.15】 Ubuntupip install xgboost（有毒） Pandas 【2018.09.13】 关于reshape总结123456# 行向量转列向量np.array([1, 2, 3]).reshape(-1, 1)Out:array([[1], [2], [3]]) Hexo 【2018.11.20】 LF will be replaced by CRLF 参考链接LF will be replaced by CRLF in git - Explanation Example 1The file will have its original line endings in your working directory. warning: LF will be replaced by CRLF in Somefile. 警告原因：Unix系统中，行末用LF(line feed, 换行)表示，而Windows中，行末用CRLF(carriage return and line feed, 回车换行)表示。core.autocrlf可实现自动转换。 1git config --global core.autocrlf true 所以，这个警告信息是不会有任何影响的，如果不愿意Git自动帮你转化，可设置为false，也就没有警告信息了。 1git config --global core.autocrlf false Python 【2019.01.10】import搜索路径 sys.path 当前目录 $PYTHONPATH 默认路径 【2019.01.10】__init__.py __init__.py为空时，标识文件夹是一个package，package内的submodule或subpackage均可被import __init__.py不为空时，只有__init__.py内的item可以被import 使用from package import *时，如果__init__.py中定义了__all__变量，则仅有这个list中的item能被import，否则均可被import]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python实现自动挂机脚本]]></title>
    <url>%2F20170825%2F12_auto_yys%2F</url>
    <content type="text"><![CDATA[使用Python + win32api实现简单自动鼠标点击 使用tkinter设计GUI界面并用pyinstaller打包 不知不觉肝阴阳师也快一年了，对这游戏真是又爱又恨，最近刚刚发布了PC版，突然很想尝试着写个脚本挂机，话不多说进入正题。 基础模拟点击简单的鼠标操作游戏挂机脚本，无非就是自动移动鼠标，自动点击，进行重复操作，所以，第一步就是如何控制鼠标 1234567891011121314import win32apiimport timedef move_click(x, y, t=0): # 移动鼠标并点击左键 win32api.SetCursorPos((x, y)) # 设置鼠标位置(x, y) win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN | win32con.MOUSEEVENTF_LEFTUP, x, y, 0, 0) # 点击鼠标左键 if t == 0: time.sleep(random.random()*2+1) # sleep一下 else: time.sleep(t) return 0# 测试move_click(30, 30) 当然，再后续操作中你可能需要获取屏幕分辨率，我只打算让脚本能在自己电脑上跑就满足了，所以没有实现适配不同分辨率 12def resolution(): # 获取屏幕分辨率 return win32api.GetSystemMetrics(0), win32api.GetSystemMetrics(1) 值得注意的是，一定要在管理员权限下的cmd中运行，否则点击无效 这个时候，你已经可以写个while循环，不停地点击屏幕上不同的几个点了，最基础的挂机脚本就实现了 使用PIL识别图像我们肯定不满足于机械式的连续点击，万一被封号呢…所以需要识别图像，再进行点击首先，就需要定位到阴阳师的窗口 12345678910import win32guidef get_window_info(): # 获取阴阳师窗口信息 wdname = u'阴阳师-网易游戏' handle = win32gui.FindWindow(0, wdname) # 获取窗口句柄 if handle == 0: # text.insert('end', '小轩提示：请打开PC端阴阳师\n') # text.see('end') # 自动显示底部 return None else: return win32gui.GetWindowRect(handle) get_window_info()函数返回阴阳师窗口信息(x1, y1, x2, y2)，(x1, y1)是窗口左上角的坐标，(x2, y2)是窗口右下角的坐标，代码中的text可以暂时忽略，这在后续GUI界面中用于输出提示信息。下面使用PIL获取游戏截图 123456789101112def get_posx(x, window_size): # 返回x相对坐标 return (window_size[2] - window_size[0]) * x / 870def get_posy(y, window_size): # 返回y相对坐标 return (window_size[3] - window_size[1]) * y / 520topx, topy = window_size[0], window_size[1]img_ready = ImageGrab.grab((topx + get_posx(500, window_size), topy + get_posy(480, window_size), topx + get_posx(540, window_size), topy + get_posy(500, window_size)))# 查看图片im_ready.show() 考虑到窗口大小不同，位置会有所偏移，这里使用屏幕上点的相对位置获取到关键位置的截图之后，计算图片的hash值 12345def get_hash(img): img = img.resize((16, 16), Image.ANTIALIAS).convert('L') # 抗锯齿 灰度 avg = sum(list(img.getdata())) / 256 # 计算像素平均值 s = ''.join(map(lambda i: '0' if i &lt; avg else '1', img.getdata())) # 每个像素进行比对,大于avg为1,反之为0 return ''.join(map(lambda j: '%x' % int(s[j:j+4], 2), range(0, 256, 4))) 将关键位置截图的hash值保存下来，下次脚本运行时，将截图hash值与原始hash值进行比对，判断是否相似。这里使用汉明距离进行计算，比较hash值中相同位置上不同元素的个数 123456def hamming(hash1, hash2, n=20): b = False assert len(hash1) == len(hash2) if sum(ch1 != ch2 for ch1, ch2 in zip(hash1, hash2)) &lt; n: b = True return b 准备工作做完了，下面就可以开心刷御灵了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def yu_ling(window_size): global is_start topx, topy = window_size[0], window_size[1] state = [] while is_start: # print 'start' # text.insert('end', 'start') time.sleep(0.5) img_ready = ImageGrab.grab((topx + get_posx(750, window_size), topy + get_posy(465, window_size), topx + get_posx(840, window_size), topy + get_posy(500, window_size))) if hamming(get_hash(img_ready), ready_hash, 10): state.append(0) move_click(topx + get_posx(740, window_size), topy + get_posy(380, window_size)) text.insert('end', strftime('%H:%M:%S', localtime()) + ' 点击准备\n') text.see('end') # 自动显示底部 time.sleep(15) continue img_success = ImageGrab.grab((topx + get_posx(400, window_size), topy + get_posy(320, window_size), topx + get_posx(470, window_size), topy + get_posy(400, window_size))) if hamming(get_hash(img_success), success_hash): time.sleep(2) state.append(1) text.insert('end', strftime('%H:%M:%S', localtime()) + ' 成功%d次\n' % state.count(1)) text.see('end') # 自动显示底部 move_click(topx + get_posx(730, window_size), topy + get_posy(380, window_size)) continue img_fail = ImageGrab.grab((topx + get_posx(560, window_size), topy + get_posy(340, window_size), topx + get_posx(610, window_size), topy + get_posy(390, window_size))) if hamming(get_hash(img_fail), fail_hash): time.sleep(2) state.append(2) text.insert('end', strftime('%H:%M:%S', localtime()) + ' 失败%d次\n' % state.count(2)) text.see('end') # 自动显示底部 move_click(topx + get_posx(720, window_size), topy + get_posy(380, window_size)) continue img_attack = ImageGrab.grab((topx + get_posx(615, window_size), topy + get_posy(350, window_size), topx + get_posx(675, window_size), topy + get_posy(375, window_size))) if hamming(get_hash(img_attack), yu_attack_hash): move_click(topx + get_posx(670, window_size), topy + get_posy(365, window_size)) text.insert('end', strftime('%H:%M:%S', localtime()) + ' 点击进攻\n') text.see('end') # 自动显示底部 state.append(3) if state[-6:] == [3]*6: text.insert('end', strftime('%H:%M:%S', localtime()) + ' 痴汉券可能不够了\n') text.see('end') # 自动显示底部 click() break continue 至此，我们已经可以通过管理员cmd运行脚本了。但这样的脚本运行起来比较麻烦，也没有好看的界面。接下来，我们将使用tkinter设计GUI界面，并用pyinstaller打包成.exe文件 GUItkintertkinter是Python内置的GUI设计界面，对小白来说容易上手，你也可以尝试用pyqt或者wx关于tkinter可以看一下莫烦教程 首先创建一个窗口，并设置必要信息12345678910111213141516import tkinter as tkfrom icon import imgwindow = tk.Tk() # 创建一个窗口window.title('奴良小轩v0.1')window.geometry('240x480+120+30') # 窗口的位置以及大小# 设置图标with open('tmp.ico', 'wb+') as fp: fp.write(base64.b64decode(img))window.iconbitmap('tmp.ico')os.remove('tmp.ico')# 设置图标label = tk.Label(window, font=('微软雅黑', 12), text='请将PC端阴阳师调节与小宝等高') # 显示一段文本label.pack() 设置图标默认情况下，窗口图标是红色的TK，想修改则使用.iconbitmap(path)方法，但是，在实际使用踩坑了。因为后面我会使用pyinstaller打包，因为找不到path路径运行程序会报错，找了好久才找到这个错误。解决方案是先将图标读取并写入ico.py文件，调用.iconbitmap(path)时读取ico.py，代码如下： 12345678import base64open_icon = open('yaodao.ico', 'rb')b64str = base64.b64encode(open_icon.read())open_icon.close()write_data = "img = '%s'" % b64strf = open('icon.py', 'w+')f.write(write_data)f.close() 功能选择1234567891011121314151617181920212223242526272829303132333435# Radiobutton #fun_var = tk.IntVar()fun_text = ''def print_selection(): global fun_text if fun_var.get() == 1: fun_text = '寮突破' elif fun_var.get() == 2: fun_text = '御灵、业原火' elif fun_var.get() == 3: fun_text = '魂十队员(未完成)' elif fun_var.get() == 4: fun_text = '魂十队长(未完成)' elif fun_var.get() == 5: fun_text = '狗粮队员(未完成)' label.config(text='功能选择： ' + fun_text)rb1 = tk.Radiobutton(window, text='寮突破', font=('微软雅黑', 10), variable=fun_var, value=1, command=print_selection)rb1.place(x=15, y=30)rb2 = tk.Radiobutton(window, text='御灵、业原火', font=('微软雅黑', 10), variable=fun_var, value=2, command=print_selection)rb2.place(x=15, y=60)rb3 = tk.Radiobutton(window, text='魂十队员', font=('微软雅黑', 10), variable=fun_var, value=3, command=print_selection)rb3.place(x=15, y=90)rb4 = tk.Radiobutton(window, text='魂十队长', font=('微软雅黑', 10), variable=fun_var, value=4, command=print_selection)rb4.place(x=15, y=120)rb5 = tk.Radiobutton(window, text='狗粮队员', font=('微软雅黑', 10), variable=fun_var, value=5, command=print_selection)rb5.place(x=15, y=150)# Radiobutton # 开始按钮 start_mission()中定义了每一个功能所要执行的函数，注意的是，独立功能需要放在一个线程中执行，不然界面会被阻塞卡死 全局变量is_start用来控制功能的执行与停止 click()函数用来改变按钮显示以及锁定功能选择 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# button start#rb_list = [rb1, rb2, rb3, rb4, rb5]button_var = tk.StringVar()button_var.set('开始')is_click = Falsedef start_mission(): global is_start if fun_var.get() == 1: text.insert('end', strftime('%H:%M:%S', localtime()) + ' 开始执行寮突破\n') text.see('end') # 自动显示底部 window_size = get_window_info() if window_size: # 打开了阴阳师 window.geometry('240x480+%d+%d' % (window_size[0]-240, window_size[1])) is_start = True thread1 = threading.Thread(target=liao_tupo, args=(window_size,)) thread1.start() elif fun_var.get() == 2: text.insert('end', strftime('%H:%M:%S', localtime()) + ' 开始执行御灵、业原火\n') text.see('end') # 自动显示底部 window_size = get_window_info() if window_size: # 打开了阴阳师 window.geometry('240x480+%d+%d' % (window_size[0] - 240, window_size[1])) is_start = True thread2 = threading.Thread(target=yu_ling, args=(window_size,)) thread2.start() elif fun_var.get() == 3: text.insert('end', strftime('%H:%M:%S', localtime()) + ' 魂十队员功能未开发\n') text.see('end') # 自动显示底部 elif fun_var.get() == 4: text.insert('end', strftime('%H:%M:%S', localtime()) + ' 魂十队长功能未开发\n') text.see('end') # 自动显示底部 elif fun_var.get() == 5: text.insert('end', strftime('%H:%M:%S', localtime()) + ' 狗粮队员功能未开发\n') text.see('end') # 自动显示底部def stop_mission(): global is_start is_start = False text.insert('end', strftime('%H:%M:%S', localtime()) + ' 停止执行\n') text.see('end') # 自动显示底部def click(): global is_click if not is_click: is_click = True button_var.set('停止') label.config(text=fun_text + ' 已经开始') for rb in rb_list: # 将选项锁定 rb.config(state='disabled') button_adjust.config(state='disabled') start_mission() else: is_click = False button_var.set('开始') label.config(text=fun_text + ' 已经停止') for rb in rb_list: rb.config(state='active') button_adjust.config(state='active') stop_mission()button = tk.Button(window, textvariable=button_var, width=10, height=1, command=click)button.place(x=140, y=60)# button start# 文本显示1234import ScrolledTexttext = ScrolledText.ScrolledText(window, width=29, height=17) # 滚动输出文本框# text = tk.Text(window, width=29, height=17) # 输出文本框text.place(x=15, y=180) 注意的一点是，再每次输出文本的时候希望自动显示低端，这时需要在insert之后执行text.see(&#39;end&#39;) Pyinstaller打包1pyinstaller -F -w -i ./yaodao.ico ./tk_gui.py -F表示输出单文件exe -w表示不显示命令行 -i设置图标 更多参数设置详见这里 至此全部搞定，打开exe时记得右键管理员权限打开 Have Fun！ 下一篇，简单碎片登记系统（鸽了）]]></content>
      <categories>
        <category>不务正业</category>
      </categories>
      <tags>
        <tag>游戏脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git安装与基本使用]]></title>
    <url>%2F20170816%2F11_git_note%2F</url>
    <content type="text"><![CDATA[Git基本使用与备忘录 安装 Windows 下载Git 双击安装，一路next linux sudo apt-get install git 配置用户 12git config --global user.name 'zydarChen'git config --global user.email 'zydarChen@outlook.com' 生成ssh key 1ssh-keygen -t rsa -C 'zydarChen@outlook.com' 与GitHub、Coding连接首先将id_rsa.pub内容复制进账户SSH Key 12ssh -T git@github.comssh -T git@git.coding.net Git备忘录 targe code 查看当前git状态 git status -s commit合并到上一个commit git commit —amend —no-edit 显示所有commit记录 git log —oneline 某个文件回到add之前（工作区不变） git reset filename 回到上个commit（工作区改变） git reset —hard HEAD 回到特定commit git reset —hard c6762a1 某个文件回到特定commit git checkout c6762a1 — 1.py 查看所有commit id git reflog .gitignore文件 基础规则 #注释行 dir/忽略dir文件夹 *.zip忽略zip文件 ignore.md忽略单个文件 !不忽略 doc/*.md忽略doc/目录下所有的.md文件，但不包括其他子目录下的.md文件 文件夹忽略规则 data: 匹配根目录以及所有子目录中名字为“data”的文件或者文件夹 data/: 匹配根目录以及所有子目录中名字为“data”的文件夹 data/*: 匹配根目录中名字为“data”的文件夹 */data/*: 匹配所有子目录中名字为“data”的文件夹 部分忽略某个文件夹(data) 不要在根目录.gitignore中配置 在data中新建.gitignore文件12/*!README.md Git学习笔记参考： 廖雪峰Git教程 莫烦PythonGit版本管理 1234567891011121314git clone https://github.com/scut-githuber/os-util.git # clone repository到本地cd gitDirgit init # 初始化空的Git仓库repositorygit add filename # 将文件添加到repositorygit add -A # 添加所有文件到repositorygit commit -m "wrote a readme file" # 提交并写提交说明git status # 查看已修改文件git diff filename # 查看filename被修改的内容git log [--pretty=oneline]# 查看提交日志git reset --hard HEAD^ # 滚回上一版本git reset --hard 3628164 # 指定ID回滚或者重做，`3628164`是commit id，git自动补全git reflog # 查看命令历史，可以查看各个版本的commit idgit checkout -- name # 让这个文件回到最近一次git commit或git add时的状态。git reset HEAD filename # 将filename从暂存区退回工作区 工作区和暂存区 工作区:工作目录，如gitDir 版本库：工作区中的隐藏目录.git 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 流程图 初始在工作目录中添加’test.py’文件，文件处于’untracked’状态：红色的’??’ 12$ git status -s?? test.py add之后，文件处于’staged’状态：绿色的’A’ 123git add test.py$ git status -sA test.py commit之后，文件处于’unmodified’状态，working tree clean git log --oneline查看commit记录。查看使用reset可回到之前版本，git reset --hard HEAD^，此时工作目录中’test.py’文件将被删除。 add之后，修改’test.py’文件内容，文件处于’modified’状态：绿色的’A’——表示新增文件操作已添加至暂存区，可提交，红色的’M’——表示修改操作仍位于工作区，不可提交。此时执行commit只会提交新增文件操作。12345$ git status -sAM test.py$ git commit -m 'test.py'$ git status -sM test.py 撤销修改 场景1：当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。 场景2：当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步，第一步用命令git reset HEAD file，就回到了场景1，第二步按场景1操作。 场景3：已经提交了不合适的修改到版本库时，想要撤销本次提交，在没有推送到远程库的前提下，git reset --hard HEAD^滚回上一版本。 误删与恢复git checkout -- test.txtgit checkout其实是用版本库里的版本替换工作区的版本，无论工作区是修改还是删除，都可以“一键还原”。 分支使用 git branch：查看分支 git branch &lt;name&gt;：创建分支 git checkout &lt;name&gt;：切换分支 git checkout -b &lt;name&gt;：创建并切换分支 git merge &lt;name&gt;：合并某分支到当前分支 git merge --no-ff -m &quot;merge with no-ff&quot; &lt;name&gt;:强制禁用Fast forward模式，不丢掉分支信息 git branch -d &lt;name&gt;：删除分支 bug分支当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场。 git stash:”储存”当前工作现场 git stash list:查看已储存现场 git stash apply:恢复现场 git stash pop：恢复现场并产出储存 经验总结 先在GitHub上建好repository，git clone 到本地 鼓励大量使用分支 通过创建bug分支的方式来修复bug 开发一个新feature，最好新建一个分支]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习基石》学习笔记——1.2 learning to answer yes/no]]></title>
    <url>%2F20170730%2F10_ML_foundations_2%2F</url>
    <content type="text"><![CDATA[handout slides Machine Learning Foundations 课程由台湾大学NTU林轩田老师开设，课程共16篇，包括四部分内容： When can machines learn? (illustrative + technical) Why can machines learn? (theoretical + technical) How can machines learn? (technical + practical) How can machines learn better? (practical + theoretical) 下面是Topic 1 Part 2——learning to answer yes/no 1. Perceptron Hypothesis Set 引入信用卡的例子，银行如何根据用户信息来决定是否给用户发放信用卡。 A Simple Hypothesis Set: the Perceptron 每个用户信息形成d维向量$\mathbf{x} = (x_1, x_2, …, x_d)$； 每个特征赋予不同的权值$w_i$，表示该特征对是否发放信用卡的影响； 所有特征的加权求和与一设定的阈值进行比较，大于阈值输出+1，即发放信用卡；小于阈值输出-1，不发放信用卡 令$x_0 = +1, w_0 = -threshold$，将阈值吸收进$\mathbf{w}^T$，则： $h(x) = sign(\sum_{i=0}^{d}w_ix_i) = sign(\mathbf{w}^T\mathbf{x})$ 2. Perceptron Learning Algorithm (PLA)在Perceptron中，hypothesis set由许多直线构成，PLA的目的就是在这些可能是无限的直线中，选择一条最好的直线，能将平面上所有的正类和负类完全分开，也就是找到最好的g，使$g \approx f$ 遍历所有可能的直线是不现实的，思路是采用“逐点修正” 基于一条直线，找到错误的点，并更新$w$，更新方法是： 如果错误点的$y = +1$，即正类误判为负类$\mathbf{w}_{(t)}\mathbf{x}_{n(t)} &lt; 0$，则表示$\mathbf{w}$与$\mathbf{x}$夹角大于90，修正方案是将角度变小，即$\mathbf{w} = \mathbf{w} + y\mathbf{x}, y=+1$； 如果错误点的$y = -1$，即负类误判为正类$\mathbf{w}_{(t)}\mathbf{x}_{n(t)} &gt; 0$，则表示$\mathbf{w}$与$\mathbf{x}$夹角小于90，修正方案是将角度变大，即$\mathbf{w} = \mathbf{w} + y\mathbf{x}, y=-1$； 如果数据本身是线性可分的，经过不断的迭代修正之后，所有的点都能正确分类 我们由$\mathbf{w}_{t+1} \leftarrow \mathbf{w}_t + y_n\mathbf{x}_n$，两边同时乘以$y_n\mathbf{x}_n$得到$y_n \mathbf{w}_{t+1}\mathbf{x}_n \leftarrow y_n \mathbf{w}_t\mathbf{x}_n + (y_n\mathbf{x}_n)^2$则有：$y_n \mathbf{w}_{t+1}\mathbf{x}_n \geqslant y_n \mathbf{w}_t\mathbf{x}_n$上式表明，随着迭代的进行，正确分类的样本逐渐变多the rule somewhat ‘tries to correct the mistake’. 3. Guarantee of PLA如果D不是线性可分的（linear separable），则PLA不会停止在线性可分的情况下，则存在$\mathbf{w}_f$使得$y_n = sing(\mathbf{w}_f^T \mathbf{x}_n)$成立 \min_n \ y_n \mathbf{w}_f^T \mathbf{x}_n > 0 \Leftrightarrow y_{n(t)} \mathbf{w}_f^T \mathbf{x}_{n(t)} \geqslant \min_n \ y_n \mathbf{w}_f^T \mathbf{x}_n > 0 也就是说，$\mathbf{w}_f^T \mathbf{w}_t$逐渐变大，内积越大似乎就表示两个向量越接近，其实不然，有可能是长度更接近了，而不是角度。所以，下面再证明长度关系。有错才更新，所以下面这个式子成立 可以看出，$\mathbf{w}_t$的增长被限制了，$\mathbf{w}_{t+1}$与$\mathbf{w}_t$向量的长度不会差别太大。 如果令初始权重$\mathbf{w}_0 = 0$，那么经过T次错误修正后，有如下结论： \frac{\mathbf{w}_f^T}{\left \|\mathbf{w}_f \right \|}\frac{\mathbf{w}_T}{\left \|\mathbf{w}_T \right \|} \geqslant \sqrt{T}\cdot constant总结： 线性可分：$\mathbf{w}_f^T$与$\mathbf{w}_t$接近 逐点纠错：$\mathbf{w}_t$长度缓慢成长 最终，PLA会停下来 4. Non-Separable Data 对于非线性的问题，PLA不会停止。 找到的“线”犯的错误最少 事实证明，上面的解是NP-hard问题，难以求解。 Packet Algorithm是对PLA的变形 “贪心”：把最好的“线”抓在手上modify PLA algorithm (black lines) by keeping best weights in pocket 一般情况下，Pocket Algorithm要比PLA速度慢一些。 附录：PLA收敛性证明]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《机器学习基石》学习笔记——1.1 the learning problem]]></title>
    <url>%2F20170727%2F9_ML_foundations_1%2F</url>
    <content type="text"><![CDATA[handout slides Machine Learning Foundations 课程由台湾大学NTU林轩田老师开设，课程共16篇，包括四部分内容： When can machines learn? (illustrative + technical) Why can machines learn? (theoretical + technical) How can machines learn? (technical + practical) How can machines learn better? (practical + theoretical) 下面是Topic 1 Part 1——the learning problem 0. Course Introductionfoundation oriented and story-like 1. What is Machine Learning learning VS Machine Learning learning: observations -&gt; learning -&gt; skill Machine Learning: data -&gt; ML -&gt; skill skill: import some performace measure, 提高某一性能 使用ML的三个关键条件： 事物本身存在某种规律 难以通过简单编程解决 有数据可供使用 2. Applications of Machine LearningML is everywhere食、衣、住、行、育、乐 3. Components of Machine Learning 基本术语 hypothesis g VS target f f是目标函数，反映问题的真实规律，但f一般是未知的； g是通过算法A得出的假设函数，我们希望g尽可能与f接近 hypothesis set H 假设集，一般一个问题对应了多个假设，这些假设形成假设集H，从H中找出最佳的g。 ML流程图 训练数据D满足未知的目标函数f 机器学习的过程，就是根据先验知识选择模型，该模型对应的hypothesis set（用H表示），H中包含了许多不同的hypothesis，通过演算法A，在训练样本D上进行训练，选择出一个最好的hypothesis，对应的函数表达式g就是我们最终要求的。 Machine Learning: use data to compute hypothesis g that approximates target f A takes D and H to get g 4. Machine Learning and Other Fields与ML相关的领域： Data Mining: use (huge) data to find property that is interestingdifficult to distinguish ML and DM in reality Artificial Intelligence: compute something that shows intelligent behaviorML is one possible route to realize AI Statistics: use data to make inference about an unknown processmany useful tools for ML]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GoogleML系列视频笔记]]></title>
    <url>%2F20170726%2F8_GoogleML_note%2F</url>
    <content type="text"><![CDATA[GoogleML系列目前共七个短视频，内容通俗易懂 Lesson1 Hello World123456from sklearn import treefeatures = [[140, 1], [130, 1], [150, 0], [170, 0]]labels = [1, 1, 1, 1]clf = tree.DecisionTreeClassifier()clf = clf.fit(features, labels)print clf.predict([150, 0]) Lesson 2 Visualizing a Decision TreeWhy decision Tree easy to read and understand Iris(Wiki) 经典的ML问题，花类型识别 四个features，三个labels 直接从sklearn导入 1234567# 查看数据from sklearn.datasets import load_irisiris = load_iris()print iris.feature_namesprint iris.target_namesprint iris.data[0]print iris.target[0] [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;] [&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;] [ 5.1 3.5 1.4 0.2] 0 123456789101112131415161718192021# 建立决策树分类器import numpy as npfrom sklearn.datasets import load_irisfrom sklearn import treeiris = load_iris()# 测试集索引，每个类取一个example作为测试集test_idx = [0, 50, 100]# training datatrain_target = np.delete(iris.target, test_idx)train_data = np.delete(iris.data, test_idx, axis=0)# testing datatest_target = iris.target[test_idx]test_data = iris.data[test_idx]clf = tree.DecisionTreeClassifier()clf.fit(train_data, train_target)print test_targetprint clf.predict(test_data) [0 1 2] [0 1 2] Visualize 可视化使用pydot pip install pydotplus conda install graphviz GraphViz’s executables not found 下载graphviz 安装，记下安装路径，如C:\Program Files (x86)\Graphviz2.38\bin 将路径添加到系统环境变量 重启IDE 123456789from IPython.display import Imageimport pydotplusdot_data = tree.export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names=iris.target_names, filled=True, rounded=True, special_characters=True) graph = pydotplus.graph_from_dot_data(dot_data)Image(graph.create_png(), width=500, height=500) Lesson 3 What Makes a Good Feature 多个feature能更好的训练模型 重复特征应当删除，否则分类器会多次使用相同特征，导致该特征被强调 feature分布越均匀，该feature对分类的作用越弱 feature应相互独立 feature应预处理，如经纬度信息经过转化可以形成距离等 总结 informative independent simple 123456789101112import numpy as npimport matplotlib.pyplot as plt# 构造500只greyhounds和500只labsgreyhounds = 500labs = 500grey_height = 28 + 4 * np.random.randn(greyhounds)lab_height = 24 + 4 * np.random.randn(labs)plt.hist([grey_height, lab_height], stacked=True, color=['r', 'b'])plt.show() Lesson 4 Let’s Write a Pipeline 划分训练集跟测试集，在训练集上训练，测试集上验证 调用sklearn.cross_validation.train_test_split切分数据集 本质上，是学习feature到label，从输入到输出的函数 神经网络演示playground 12345678910111213141516171819202122232425# import a datasetfrom sklearn import datasetsiris = datasets.load_iris()X = iris.datay = iris.target# splitfrom sklearn.cross_validation import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)from sklearn import treefrom sklearn.neighbors import KNeighborsClassifiertree_clf = tree.DecisionTreeClassifier()kn_clf = KNeighborsClassifier()tree_clf.fit(X_train, y_train)kn_clf.fit(X_train, y_train)tree_pred = tree_clf.predict(X_test)kn_pred = kn_clf.predict(X_test)from sklearn.metrics import accuracy_scoreprint 'tree_clf accuracy:', accuracy_score(y_test, tree_pred)print 'kn_clf accuracy:', accuracy_score(y_test, kn_pred) tree_clf accuracy: 0.946666666667 kn_clf accuracy: 0.986666666667 Lesson 5 Writing Our First Classifier简单的随机分类器12345678910111213141516171819202122232425262728293031import randomclass random_clf(): def fit(self, X_train, y_train):# pass self.X_train = X_train self.y_train = y_train def predict(self, X_test):# pass predictions = [] for row in X_test: label = random.choice(self.y_train) predictions.append(label) return predictions# import a datasetfrom sklearn import datasetsiris = datasets.load_iris()X = iris.datay = iris.target# splitfrom sklearn.cross_validation import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)clf = random_clf()clf.fit(X_train, y_train)clf_pred = clf.predict(X_test)from sklearn.metrics import accuracy_scoreprint 'accuracy:', accuracy_score(y_test, clf_pred) accuracy: 0.36 KNN (K-Nearest Neighbour) 考虑测试点的近邻K个点，K个点中，属于某一类最多，则该点属于该类 距离公式，平方和开方 注意： 实现时先确定接口(fit, predict) 对每个接口实现时先确定输入输出 K = 1 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from scipy.spatial import distance# 计算a, b之间的距离def euc(a,b): return distance.euclidean(a, b)class knn_clf(): def fit(self, X_train, y_train):# pass self.X_train = X_train self.y_train = y_train def predict(self, X_test):# pass predictions = [] for row in X_test: label = self.closest(row) predictions.append(label) return predictions def closest(self, row): best_dist = euc(row, self.X_train[0]) best_index = 0 for i in range(1, len(self.X_train)): dist = euc(row, self.X_train[i]) if dist &lt; best_dist: best_dist = dist best_index = i return self.y_train[best_index]# import a datasetfrom sklearn import datasetsiris = datasets.load_iris()X = iris.datay = iris.target# splitfrom sklearn.cross_validation import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)clf = knn_clf()clf.fit(X_train, y_train)clf_pred = clf.predict(X_test)from sklearn.metrics import accuracy_scoreprint 'accuracy:', accuracy_score(y_test, clf_pred) accuracy: 0.986666666667 Lesson 6 Train an Image Classifier with TensorFlow for PoetsNo feature engineering needed!!!数据 五种花图片 218MB 如果你想要用其他的图片类型，你只需要创建一个新的文件夹，放入对应类型的100张以上的图片 Diversity and quantity Diversity：样本多样性越多，对新事物的预测能力越强 Quantity：样本数量越多，分类器越强大 以下代码在Linux下执行 12345678910111213141516171819202122from sklearn import datasets, cross_validation# tensorflow 1.1.0import tensorflow as tf# load datesetstf.logging.set_verbosity(tf.logging.ERROR) # 忽略其他日志信息iris = datasets.load_iris()X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.2)# Construct DNN# Specify that all features have real-value datafeature_columns = [tf.contrib.layers.real_valued_column('', dimension=4)]# Build 3 layer DNN with 10, 20, 10 units respectively.classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns, # 指定数据特征，维数4 hidden_units=[10, 20, 10], # Three hidden layers, containing 10, 20, and 10 neurons, respectively. n_classes=3, # 三类 model_dir='/tmp/iris_model')classifier.fit(x=X_train, y=y_train, steps=1000)score = classifier.evaluate(x=X_test, y=y_test, steps=1)['accuracy']print('\nTest Accuracy: &#123;0:f&#125;\n'.format(score)) Test Accuracy: 1.000000 Lesson 7 Classifying Handwritten Digits with TF.Learnmnist问题 the Hello World of computer vision 训练集55,000，测试集10,000，每张图片处理成28*28的二维矩阵，784 features 十分类问题 123456import numpy as npimport matplotlib.pyplot as plt%matplotlib inlineimport tensorflow as tflearn = tf.contrib.learntf.logging.set_verbosity(tf.logging.ERROR) Import the dataset12345678910mnist = learn.datasets.load_dataset('mnist')data = mnist.train.imageslabels = np.asarray(mnist.train.labels, dtype=np.int32)test_data = mnist.test.imagestest_labels = np.asarray(mnist.test.labels, dtype=np.int32)# 减少数据max_examples = 10000data = data[:max_examples]labels = labels[:max_examples] Extracting MNIST-data/train-images-idx3-ubyte.gz Extracting MNIST-data/train-labels-idx1-ubyte.gz Extracting MNIST-data/t10k-images-idx3-ubyte.gz Extracting MNIST-data/t10k-labels-idx1-ubyte.gz 显示1234567def display(i): img = test_data[i] plt.title('Example %d. Label: %d' % (i, test_labels[i])) plt.imshow(img.reshape((28,28)), cmap=plt.cm.gray_r)display(0)print 'number of features is', len(data[0]) number of features is 784 fit a Linear Classifier123456feature_columns = learn.infer_real_valued_columns_from_input(data)classifier = learn.LinearClassifier(feature_columns=feature_columns, n_classes=10)classifier.fit(data, labels, batch_size=100, steps=1000)classifier.evaluate(test_data, test_labels)print classifier.evaluate(test_data, test_labels)['accuracy'] 0.9137 Visualize learned weights12345678910weights = classifier.weights_f, axes = plt.subplots(2, 5, figsize=(10,4))axes = axes.reshape(-1)for i in range(len(axes)): a = axes[i] a.imshow(weights.T[i].reshape(28, 28), cmap=plt.cm.seismic) a.set_title(i) a.set_xticks(()) # ticks be gone a.set_yticks(())plt.show() --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-32-13532f014713&gt; in &lt;module&gt;() ----&gt; 1 weights = classifier.weights_ 2 f, axes = plt.subplots(2, 5, figsize=(10,4)) 3 axes = axes.reshape(-1) 4 for i in range(len(axes)): 5 a = axes[i] AttributeError: &#39;LinearClassifier&#39; object has no attribute &#39;weights_&#39; 附录代码分析 From ahangchen代码分析 下载数据集 1mnist = learn.datasets.load_dataset('mnist') 恩，就是这么简单，一行代码下载解压mnist数据，每个img已经灰度化成长784的数组，每个label已经one-hot成长度10的数组 numpy读取图像到内存，用于后续操作，包括训练集（只取前10000个）和验证集 1234567data = mnist.train.imageslabels = np.asarray(mnist.train.labels, dtype=np.int32)test_data = mnist.test.imagestest_labels = np.asarray(mnist.test.labels, dtype=np.int32)max_examples = 10000data = data[:max_examples]labels = labels[:max_examples] 可视化图像 12345def display(i): img = test_data[i] plt.title('Example %d. Label: %d' % (i, test_labels[i])) plt.imshow(img.reshape((28, 28)), cmap=plt.cm.gray_r) plt.show() 用matplotlib展示灰度图 训练分类器 提取特征（这里每个图的特征就是784个像素值） 1feature_columns = learn.infer_real_valued_columns_from_input(data) 创建线性分类器并训练 12classifier = learn.LinearClassifier(feature_columns=feature_columns, n_classes=10)classifier.fit(data, labels, batch_size=100, steps=1000) 注意要制定n_classes为labels的数量 分类器实际上是在根据每个feature判断每个label的可能性， 不同的feature有的重要，有的不重要，所以需要设置不同的权重 一开始权重都是随机的，在fit的过程中，实际上就是在调整权重 最后可能性最高的label就会作为预测输出 传入测试集，预测，评估分类效果 12result = classifier.evaluate(test_data, test_labels)print result["accuracy"] 速度非常快，而且准确率达到91.4% 可以只预测某张图，并查看预测是否跟实际图形一致 123456# here's one it gets rightprint ("Predicted %d, Label: %d" % (classifier.predict(test_data[0]), test_labels[0]))display(0)# and one it gets wrongprint ("Predicted %d, Label: %d" % (classifier.predict(test_data[8]), test_labels[8]))display(8) 可视化权重以了解分类器的工作原理 12weights = classifier.weights_a.imshow(weights.T[i].reshape(28, 28), cmap=plt.cm.seismic) 这里展示了8个张图中，每个像素点（也就是feature）的weights， 红色表示正的权重，蓝色表示负的权重 作用越大的像素，它的颜色越深，也就是权重越大 所以权重中红色部分几乎展示了正确的数字]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark日常填坑]]></title>
    <url>%2F20170717%2F7_debug_spark%2F</url>
    <content type="text"><![CDATA[spark基础使用 集群spark使用jupyter notebook jupyter notebook安装 ImportError: No module named pyspark 原因是没有添加环境变量1234# spark 1.6.0export SPARK_HOME=/usr/local/sparkexport PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip# 注意py4j的版本对应 first try 123456from pyspark import SparkContext, SparkConfconf = SparkConf().setAppName('YOURNAME').setMaster('spark://mu01:7077').set('spark.executor.memory', '4G').set('spark.cores.max', '80')sc = SparkContext(conf=conf)data = [1, 2, 3, 4, 5]distData = sc.parallelize(data)print distData.first()]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Spark</tag>
        <tag>Debug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编写高质量代码]]></title>
    <url>%2F20170714%2F6_91_python_suggestions%2F</url>
    <content type="text"><![CDATA[Writing Solid Python Code—91 Suggestions to Improve Your Python Program 《改善Python程序的91个建议》读书笔记 Pythonic编程 第1章 引论 Sug 1: Pythonic，充分体现Python自身特色的代码风格。 Sug 1: 实现快速排序函数： 12345678910111213141516def quicksort(array): less = [] greater = [] if len(array) &lt;= 1: return array pivot = array.pop() for x in array: if x &lt;= pivot: less.append(x) else: greater.append(x) return quicksort(less) + [pivot] + quicksort(greater) Sug 1: Pythonic最推荐的字符串格式化方法 1print '&#123;greet&#125; from &#123;language&#125;'.format(greet = 'Hello World', language = 'Python') Sug 2: 避免劣化代码 避免只用大小写来区分不同的对象 避免使用容易引起混淆的名称 不要害怕过长的变量名 总的来说，变量名的命名应更具有实际意义 Sug 2: PEP8是一篇关于Python编码风格的指南 123pip install -U pep8pep8 --first test.pypep8 --show-source --show-pep8 test.py Sug 3: 三元操作符?等价于X if C else Y Sug 3: switch...case语句实现：if...elif...elif...else或者使用跳转表实现 12345678def f(n): return &#123; 0: 'You typed zero.\n', 1: 'You are in top.\n', 2: 'n is an even number.\n' &#125;.get(n, 'Only single-digit number are allowed.\n')# dict.get(key, default=None) Sug 4: 函数注释实例 123456789def funcName(parameter1, parameter2): """Describe what this function does. Args: parameter1:parameter type, what is this parameter used for. parameter2:parameter type, what is this parameter used for. Returns: return type, return value """ function body Sug 6: if、elif、while、for等循环语句尽量不要嵌套过深，最好能控制在3层以内。 Sug 6: 函数参数设计应该考虑向下兼容 123def readfile(filename) # 第一个版本def readfile(filename, logger) # 第二个版本，不向下兼容def readfile(filename, logger = logger.info) # 第二个版本，向下兼容 Sug 7: 将常量集中到一个文件 12345678910111213141516171819202122# coding:utf-8#class _const: class ConstError(TypeError): pass class ConstCaseError(ConstError): pass def __setattr__(self, name, value): if name in self.__dict__: raise self.ConstError("can't change const %s" % name) if not name.isupper(): raise self.ConstCaseError('const name "%s" is not all uppercase' % name) self.__dict__[name] = value ## import sys# sys.modules[__name__] = _const()const = _const()const.PI = 3.14# 在另一个.py文件中引用from const import constprint const.PI 第2章 编程惯用法 Sug 8: assert用来捕捉用户所定义的约束，而不是用来捕捉程序本身错误的 1assert x == y, 'not equals' Sug 9: 充分利用Lazy evaluation的特性 if x and y, x为false时不计算y if x or y, x为true时不计算y Sug 12: 推荐使用isinstance()检查类型，而不是type() 1isinstance('a',(str, unicode)) Sug 15: 使用enumerate()获取序列迭代的索引和值 12345678910111213for i,e in enumerate(list):# 函数原型def enumerate(sequence, start = 0): n = start for elem in sequence: yield n, elem n += 1# 反序def myenumerate(sequence): n = -1 for elem in reversed(sequence): yield len(sequence) + n, elem n = n - 1 Sug 16: is表示的是对象标识符，而==表示的意思是相等。 Sug 17: decode()将其他编码对应的字符串解码成unicode，而encode()将unicode编码转换为另一种编码。 Sug 17: 源文件编码说明# coding = utf-8 第3章 基础语法 Sug 19: import的使用 一般情况下尽量优先使用import a.B 有节制地使用from a import B 尽量避免使用from a import * Sug 22: 使用with自动关闭资源 12with open('test.text', 'w') as f:f.write('test') Sug 23: 使用else子句简化循环，当循环自然终结时else从句会被执行一次。 Sug 24: 异常处理try-except-else-finally 1234567891011121314try: &lt;statements&gt;except &lt;name1&gt;: &lt;statements&gt; # 当try中发生name1的异常时处理except (name2, name3): &lt;statements&gt; # 当try中发生name2或name3中的某一个异常时处理except &lt;name4&gt; as &lt;data&gt;: &lt;statements&gt; # 当try中发生name4的异常时处理，并获取对应实例except: &lt;statements&gt; # 其他异常发生时处理else: &lt;statements&gt; # 没有异常发生时处理finally: &lt;statements&gt; # 不管有没有异常发生都会执行 Sug 25: 不推荐在finally中使用return语句进行返回 如果finally语句中产生了新的异常或者执行了return或者break语句，那么临时保存的异常信息将会被丢失 在执行try语句块的return之前，如果finally语句块中存在return会直接返回 Sug 26: 判断列表是否为空` 12if list1: do something Sug 27: 连接字符串应优先使用join而不是+ Sug 28: 格式化字符串转换类型 转换类型 解释 c 转换为单个字符，对于数字将转换该值对应的ASCII码 + 转化为字符串，对于非字符串对象，将默认调用str()函数进行转换 r 用repr()函数进行字符串转换 i d 转换为带符号的十进制数 u 转换为不带符号的十进制数 o 转化为不带符号的八进制数 x X 转化为不带符号的十六进制 e E 表示为科学记数法表示的浮点数 f F 转成浮点数（小数部分自然截断） g G 如果指数大于-4或者小于精度值则和e/E相同，其他情况与f/F相同 Sug 30: 列表解析[expr for iter_item in iterable if cond_expr] Sug 31: 函数传参既不是传值也不是传引用，应该是传对象。根绝对象是否可变进行区分 Sug 33: 慎用变长参数 *args: 用于接受一个包装为元组形式的参数列表来传递非关键参数 **kwags: 接受字典形式的关键字参数列表 Sug 34: str()主要面向用户，其目的是可读性；repr面向的是python解释器 第4章 库 Sug 36: Python遇到未闭合的小括号时会自动将多行代码拼接为一行，并把相邻的两个字符串字面量拼接在一起 1234&gt;&gt;&gt;s = ('this is ' 'a long sentence')&gt;&gt;&gt;s'this is a long sentence' Sug 36: 判断一个变量s是不是字符串应使用isinstance(s, basestring)，basestring是str和unicode的基类 Sug 36: split()先去除字符串两端的空白字符，然后以任意长度的空白字符串作为界定符分切字符串；而split(&#39;&#39;)直接以空格作为界定符 Sug 37: sorted()函数返回一个排序后的列表，原有列表保持不变；而sort()函数会直接修改原有列表，函数返回None，因为不需要复制原有列表，效率相对较高。 12345678from operator import itemgettergameresult = [ ['Bob', 95.00, 'A'], ['Alan', 86.00, 'C'], ['Mandy', 82.50, 'A'], ['Rob', 86.00, 'E'] ]sorted(gameresult, key = itemgetter(2, 1))#output[['Mandy', 82.5, 'A'],['Bob', 95.0, 'A'],['Alan', 86.0, 'C'],['Rob', 86.0, 'E']] Sug 38: 浅拷贝和深拷贝 浅拷贝(shallow copy): 构造一个新的复合对象并将从原对象中发现的引用插入该对象中。 深拷贝(deep copy): 构造一个新的复合对象，遇到引用会继续递归拷贝其所指向的具体内容。 Sug 42: 使用pandas处理大型CSV文件 Sug 44 : 序列化，把内存中的数据结构在不丢失其身份和类型信息的情况下转成对象的文本或二进制表示的过程。从效率上，json &gt; pickle &gt; cPickle 第8章 性能剖析与优化 Sug 79: 让正确的程序更快比让快速的程序正确容易得多 Sug 81: 80/20法则，20%的代码的运行时间占用了80%的总运行时间 1234567# 略if __name__ == '__main__': import cProfile cProfile.run('foo()', 'prof.txt') import pstats p = pstats.Stats('prof.txt') p.sort_stats('time').print_stats() Sug 83: 时间复杂度比较O(1) &lt; O(log* n) &lt; O(n) &lt; O(n log n) &lt; O(n2) &lt; O(cn) &lt; O(n!) &lt; O(nn)]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter与Pycharm远程开发]]></title>
    <url>%2F20170711%2F5_remote_on_jupyter_and_pycharm%2F</url>
    <content type="text"><![CDATA[本地代码开发，远程服务器跑程序，想想是不是美滋滋呢~情景是这样的：你并没有服务器的root权限，你只是Ubuntu服务器上小小的user update: 2018.09.27 更新Pycharm2018.1.3 登陆服务器openVPN 接入内网Xshell or MobaXterm登陆服务器 方法一：直接用ssh + ip 登陆，如ssh 192.168.0.100 方法二：新建会话，“连接”中配置名称、协议、主机、端口，“用户身份认证”中配置用户名、密码，之后双击会话即可登陆服务器。 jupyter notebook安装 强烈推荐直接安装Anaconda 登陆系统之后很开心地pip install jupyter，然后开始各种权限不够，怎么办？那我想办法直接安装在用户目录行了吧，于是乎… pip怎么安装到用户目录 好像调用地还是系统的pip，权限又不够了。好吧，装一个自己的pip12wget https://bootstrap.pypa.io/get-pip.pypython get-pip.py 好像这次调用了系统的Python，于是乎…算球，先给本user装一套python，嗯，又是一番折腾，结论就是：强烈推荐直接安装Anaconda123456# Linux64位 Python-2.7.13# 其他版本自行上官网wget https://repo.continuum.io/archive/Anaconda2-4.3.1-Linux-x86_64.shchmod +x Anaconda2-4.3.1-Linux-x86_64.sh # 添加执行权限./Anaconda2-4.3.1-Linux-x86_64.sh # 安装# 接下来根据提示输入yes即可 因为Anaconda内置了jupyter，任务结束了输入jupyter notebook即可打开 配置首先生成notebook配置文件：jupyter notebook --generate-config，一般路径是~/.jupyter/jupyter_notebook_config.py，vim直接打开，配置内容如下： 12345c.NotebookApp.ip = &apos;*&apos;c.NotebookApp.notebook_dir = u&apos;/the/path/of/jupyternotebook&apos; # 配置notebook目录c.NotebookApp.open_browser = False # 默认不打开浏览器页面c.NotebookApp.password = u&apos;&apos; # notebook密码，生成方式在配置文件中有c.NotebookApp.port = 1717 # 配置端口，避免跟别人冲突嘛 万事俱备，jupyter notebook开启notebook等等，说好的本地开发呢？请打开本地浏览器，地址栏输入ip + 端口号，如192.168.0.100：1717，输入密码，log in，大功告成！不想每次都登上服务器开启jupyter？让它保持后台运行吧！ nohup jupyter notebook &amp;，注意：暂时不用的时候记得shutdown，不然内存、显存会被持续占有。 Pycharm使用PyCharm进行远程开发和调试上面的博文中已经有了图文并茂的详细说明，这里只做简单摘要总结，方便自己。 需要Pycharm专业版哟，有个学生邮箱，去JetBrains官网认证一下就行了，一年续一次 部署 Tools -&gt; Deployment -&gt; Configuration 点击+ Type选择SFTP，点击OK 第一个选项卡Connection填写主机、端口、根目录、用户名、密码 第二个选项卡Mappings填写本地项目地址，远程项目地址，第三行可留空 第三个选项卡Excluded Paths添加忽略路径 点击OK搞定，在Tools -&gt; Deployment中即可上传、下载、同步、浏览服务器文件 远程调试代码最终是在远程服务器上执行的，所以嘛，服务器上必须要有python解释器，没有的话先装一个吧 旧版Pycharm 选择File -&gt; Settings，选择Project -&gt; Project Interpreter，然后在右边，点击那个小齿轮设置，选择Add Remote 选择Deployment configuration，点击create，填入服务器python解释器路径 OK大功告成 Pycharm 2018.1.3 选择File -&gt; Settings，选择Project -&gt; Project Interpreter，然后在右边，点击那个小齿轮设置，选择Add 选择SSH Interpreter -&gt; Existing server configuration，Deployment configuration拉选刚刚创建好的SFTP，Next 设置远程Python解释器以及远程项目路径，Finish 切换如果你有多个远程服务器，可以进行随时切换，比如在GPU集群上跑深度学习，然后回到CPU集群上跑XGBOOST File -&gt; Settings，选择Project -&gt; Project Interpreter，切换远程解释器 Tools -&gt; Deployment -&gt; Configuration，选择远程解释器所在SFTP，在Mappings选项卡中点击‘Use this server as default’ 别忘了勾选上Tools -&gt; Deployment -&gt; Automatic Upload(always)哟 小问题 如果user没有远程解释器所在文件夹的权限的话，Pycharm界面可能会显示一堆飘红 如果使用GPU跑tensorflow需要配置cuda环境变量 Enjoy Yourself!]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Pycharm</tag>
        <tag>Jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello Blog]]></title>
    <url>%2F20170707%2F4_hello_blog%2F</url>
    <content type="text"><![CDATA[Hexo搭建博客问题记录 2018.01.16更新 clean-blog主题移动端效果一般，现转NexT(使用文档，Github) 参考链接： Hexo(1)-github＋hexo 建立你的第一个博客 Hexo(2)-部署博客及更新博文 初入 Git安装 Node.js安装 Hexo安装npm install hexo-cli -g Hexo初始化 123hexo init blog # blog为文件夹名hexo ghexo s # 本地预览 修改根配置文件“\blog\_config.yml” NexT主题下插件安装 12npm install hexo-generator-searchdb --savenpm install hexo-symbols-count-time --save 常用操作 1234567hexo new 'title' # 新建博文hexo new page 'page_name' # 新建页面hexo cleanhexo generate # 生成静态页面，hexo ghexo server # 本地预览http://localhost:4000，hexo shexo deploy # 发布到GitHub，hexo dhexo d -g # 生成静态页面并发布 基础篇Q1：使用https与GitHub连接失败改用ssh1234deploy: type: git repository: https://github.com/username/username.github.io.git branch: master Q2：更换Clean Blog主题1git clone https://github.com/klugjo/hexo-theme-clean-blog.git themes/clean-blog 修改_config.yml1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: clean-blog Q3：如何将某一个标签作为一个页面将/tags/该标签作为页面链接 Q4：Clean Blog添加关于页面\themes\clean-blog\layout文件夹下创建about.ejs123456789101112131415161718192021222324252627282930&lt;!-- Page Header --&gt;&lt;!-- Set your background image for this header in your post front-matter: cover --&gt;&lt;% var cover = page.cover || theme.index_cover;%&gt;&lt;header class=&quot;intro-header&quot; style=&quot;background-image: url(&apos;&lt;%- cover %&gt;&apos;)&quot;&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1&quot;&gt; &lt;div class=&quot;site-heading&quot;&gt; &lt;h1&gt;&lt;%- page.title %&gt;&lt;/h1&gt; &lt;hr class=&quot;small&quot;&gt; &lt;span class=&quot;subheading&quot;&gt;&lt;%- page.subtitle %&gt;&lt;/span&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/header&gt;&lt;!-- Post Content --&gt;&lt;article&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;!-- Post Main Content --&gt; &lt;div class=&quot;col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1&quot;&gt; &lt;%- page.content %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/article&gt; 生成about页面，修改\source\about\index.md，添加layout: about Q5：删除底部信息在\themes\clean-blog\layout\_partial\footer.ejs中修改 Q6：指定404页面将404.html文件放在\themes\clean-blog\source或\source中 自定义404页面1234567891011&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;404&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; charset=&quot;utf-8&quot; homePageUrl=&quot;http://yoursite.com/yourPage.html&quot; homePageName=&quot;回到我的主页&quot;&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 注意：如果没有绑定域名的话是自定义404页面，如腾讯公益404无法使用 hexo new page 404生成404页面，修改\source\404\index.md，hexo g生成静态页面，将生成的静态页面放在\themes\clean-blog\source或\source下，删除\source\404 Q6：显示网站缩略标志修改\themes\clean-blog\_config.yml12# set your own faviconfavicon: /img/favicon.jpg Q7：添加评论修改\themes\clean-blog\_config.yml123comments: # Disqus comments disqus_shortname: zydarChen 正常显示评论需科学上网 补充：添加其他评论，如来比力 来比力官网注册账号，根据提示获取安装代码 将代码复制到\themes\clean-blog\layout\_partial\comments.ejs即可 Q8：修改锚链接样式修改\themes\clean-blog\source\css\base.styl1234p, li a color brand-primary text-decoration none Q9：底部显示个人账号图标以及链接修改\themes\clean-blog\layout\_partial\footer.ejs，并在\themes\clean-blog\_config.yml下添加相应内容即可12# Social Accountswechat: /img/wechat.jpg 注意，由于之前Q8改过锚链接样式，而图标外圈颜色在标签p/li/a中，颜色会被修改为蓝色，直接将标签改为p/li/c，并在\themes\clean-blog\source\css\base.styl中添加相应的标签样式12345678910&lt;% if (theme.wechat) &#123; %&gt; &lt;li&gt; &lt;a href=&quot;&lt;%- theme.wechat%&gt;&quot; target=&quot;_blank&quot;&gt; &lt;span class=&quot;fa-stack fa-lg&quot;&gt; &lt;c class=&quot;fa fa-circle fa-stack-2x&quot;&gt;&lt;/c&gt; &lt;i class=&quot;fa fa-wechat fa-stack-1x fa-inverse&quot;&gt;&lt;/i&gt; &lt;/span&gt; &lt;/a&gt; &lt;/li&gt;&lt;% &#125; %&gt; Q10：页面图片宽度不一Clean Blog采用的是自适应，当内容不一致是出现这个问题。尽量保持内容模块数一致。Clean Blog主题的主页相较其他page页多出subtilte，补充即可。1234567&lt;div class=&quot;col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1&quot;&gt; &lt;div class=&quot;site-heading&quot;&gt; &lt;h1&gt;&lt;%- page.title %&gt;&lt;/h1&gt; &lt;hr class=&quot;small&quot;&gt; &lt;span class=&quot;subheading&quot;&gt;zydarChen&lt;/span&gt; &lt;/div&gt;&lt;/div&gt; 进阶篇Q11：部分文章不显示在主页如何控制文章是否在主页显示？比如，某些还只是处于草稿状态，不想放在主页，但可以归于某一标签或分类，在该分类中查看草稿。求告知。 Q12：托管到Coding，简单几步实现转移 注册Coding，最好使用注册GitHub的邮箱 ssh对接 如果coding邮箱与GitHub邮箱不同，将coding改绑到GitHub邮箱（懒人做法） 打开C:\Users\zydar\.ssh\id_rsa.pub，zydar是你电脑的用户名，复制文件内容 在coding个人主页，账户-SSH公钥，将id_rsa.pub文件内容复制进去 执行ssh -T git@git.coding.net，获得提示Hello zydar You&#39;ve connected to Coding.net by SSH successfully! 在coding上新建项目，项目名称为用户名 配置hexo，修改_config.yml 123456deploy: type: git repository: github: https://github.com/zydarChen/zydarChen.github.io.git coding: https://coding.net/zydarChen/zydarChen.git branch: master 在source/需要创建一个空白文件，至于原因，是因为coding.net需要这个文件来作为以静态文件部署的标志。就是说看到这个Staticfile就知道按照静态文件来发布。 12cd source/touch Staticfile #名字必须是Staticfile hexo g -d之后，会弹出页面填写coding.net账户密码 在coding.net进入项目，代码-Pages服务，开启服务即可 搞定，可以访问http://zydarChen.coding.me，查看你的博客了 Q13：将网站提交搜索引擎解决方案:Github(google提交)+Coding(百度提交)，自适应提交搜索引擎(绝招来啦！) Google网站验证链接 百度网站验证链接 确认收录方式：Google/百度搜索框输入site:yoursite.github.io 配置站点地图文件代码可以不添加，我添加反而出错 出现sitemap.xml文件中url为yoursite.com的情况，请检查_config.yml文件中的url:是否为网站地址 github禁止了百度爬虫，提交了百度也是不会访问的。百度验证时，通过文件验证出错也是这个原因。 如果同时托管到了coding.net，可以将百度sitemap的url改为coding的地址 进入\node_modules\hexo-generator-baidu-sitemap\baidusitemap.ejs 第三行&lt;% var url = config.url + config.root %&gt;改为&lt;% var url = config.coding_url + config.root %&gt; 修改站点_config.yml 12url: https://zydarchen.github.iocoding_url: http://zydarchen.coding.me # 添加行 hexo g之后能看到baidusitemap.xml已经自动修改 Q14：域名选路解析解决方案：Dnspod+Namesilo域名结合实现域名选路解析(精)我的解决方案： 万网上注册域名，目前已被阿里云收购 添加域名解析(我直接使用了万网提供的域名解析，也可以使用Dnspod等) Coding Pages配置，直接添加自定义域名www.zydarChen.top GitHub Pages配置，Hexo目录下建立CNAME文件，并将www.zydarChen.top写入，部署到服务器即可。在 Settings-GitHub Pages页面可看到部署成功。 按上述做法，当海外地址访问www.zydarChen.top时会解析到zydarchen.github.io，此时可能出现链接不安全/证书风险问题。这是GitHub Pages本身的问题，官方文档上写着“HTTPS is not supported for GitHub Pages using custom domains”解决方案：让个人域名下GithubPage完美支持https2018.05.01官方支持自定义域名HTTPS啦，喜大普奔，GitHub Pages Blog 原文：Custom domains on GitHub Pages gain support for HTTPS由于设置了域名选路解析，可能导致coding上申请SSL/TLS证书错误，解决方案：关闭选路解析-重新申请-开启选路解析 Q15：为页面添加阅读人数统计解决方案：Hexo统计post阅读次数我的实现： 注册LeanClound，创建Counter并记录APP ID跟APP Key 修改站点_config.yml，添加 12345# leancloudleancloud_visitors: enable: true app_id: UaWT************ app_key: U7TR*********** 修改\themes\clean-blog\layout\_partial\article-full.ejs，确定显示阅读量的位置 123456789101112&lt;span class=&quot;meta&quot;&gt; &lt;!-- Date and Author --&gt; &lt;% if(item.author) &#123; %&gt; Posted by &lt;%- item.author %&gt; on &lt;% &#125; %&gt; &lt;% if(item.date) &#123; %&gt; &lt;%= item.date.format(config.date_format) %&gt; &lt;% &#125; %&gt; &lt;!-- Lean Cloud --&gt; # 此处开始为添加部分 &lt;% if(config.leancloud_visitors.enable)&#123; %&gt; 阅读量 : &lt;span id=&quot;&lt;%= url_for(page.path) %&gt;&quot; class=&quot;leancloud_visitors&quot; data-flag-title=&quot;&lt;%- page.title %&gt;&quot;&gt;&lt;/span&gt; &lt;% &#125; %&gt;&lt;/span&gt; 修改\themes\clean-blog\layout\_partial\after-footer.ejs，添加 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- Lean Cloud --&gt;&lt;script src=&quot;//cdn1.lncld.net/static/js/2.5.0/av-min.js&quot;&gt;&lt;/script&gt;&lt;script&gt; var APP_ID = &apos;&lt;%- config.leancloud_visitors.app_id %&gt;&apos;; var APP_KEY = &apos;&lt;%- config.leancloud_visitors.app_key %&gt;&apos;; AV.init(&#123; appId: APP_ID, appKey: APP_KEY &#125;); // 显示次数 function showTime(Counter) &#123; var query = new AV.Query(&quot;Counter&quot;); if($(&quot;.leancloud_visitors&quot;).length &gt; 0)&#123; var url = $(&quot;.leancloud_visitors&quot;).attr(&apos;id&apos;).trim(); // where field query.equalTo(&quot;words&quot;, url); // count query.count().then(function (number) &#123; // There are number instances of MyClass where words equals url. $(document.getElementById(url)).text(number? number : &apos;--&apos;); &#125;, function (error) &#123; // error is an instance of AVError. &#125;); &#125; &#125; // 追加pv function addCount(Counter) &#123; var url = $(&quot;.leancloud_visitors&quot;).length &gt; 0 ? $(&quot;.leancloud_visitors&quot;).attr(&apos;id&apos;).trim() : &apos;www.zydarChen.top&apos;; # 你的网址 var Counter = AV.Object.extend(&quot;Counter&quot;); var query = new Counter; query.save(&#123; words: url &#125;).then(function (object) &#123; &#125;) &#125; $(function () &#123; var Counter = AV.Object.extend(&quot;Counter&quot;); addCount(Counter); showTime(Counter); &#125;);&lt;/script&gt; 已经搞定，但字体是斜体还是看着不舒服，修改\themes\clean-blog\source\css\base.styl，搜索italic，将相应描述删除，done Q16：字数统计WordCound 安装WordCound 1npm install hexo-wordcount --save 修改站点_config.yml，添加 1234# WordCountpost_wordcount: wordcount: true min2read: true 修改\themes\clean-blog\layout\_partial\article-full.ejs，在适当的位置添加以下代码（同Q14） 12345&lt;!-- WordCount --&gt;&lt;% if(config.post_wordcount.wordcount)&#123; %&gt; | 字数 : &lt;%= wordcount(page.content) %&gt;&lt;% &#125; %&gt;&lt;% if(config.post_wordcount.min2read)&#123; %&gt; | 阅读时长 : &lt;%= min2read(page.content) %&gt; min&lt;% &#125; %&gt; Q17：使用mathjax渲染latex如何处理Hexo和MathJax的兼容问题 安装插件 1npm install hexo-math --save 解决兼容问题 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save 测试，参考hexo-math MathJax Inline: 1Simple inline $a = b + c$. 效果：Simple inline $a = b + c$. MathJax Block: 1234$$\frac&#123;\partial u&#125;&#123;\partial t&#125;= h^2 \left( \frac&#123;\partial^2 u&#125;&#123;\partial x^2&#125; +\frac&#123;\partial^2 u&#125;&#123;\partial y^2&#125; +\frac&#123;\partial^2 u&#125;&#123;\partial z^2&#125;\right)$$ 效果： \frac{\partial u}{\partial t} = h^2 \left( \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} + \frac{\partial^2 u}{\partial z^2}\right) 添加Mathjax开关How? Q18：添加折叠块功能 Hexo next博客添加折叠块功能添加折叠代码块 jQuery 实现内容折叠功能 使用 123&#123;% fold 提示语 %&#125;折叠内容&#123;% endfold %&#125; 搬运 themes/next/source/js/src/post-details.js # 主要实现点击显/隐代码 12345678// 设置折叠快$(document).ready(function()&#123; $(document).on('click', '.fold_hider', function()&#123; $('&gt;.fold', this.parentNode).slideToggle(); $('&gt;:first', this).toggleClass('open'); &#125;); $("div.fold").css("display","none");&#125;); themes/next/scripts/fold.js # 使用内建标签点击显/隐代码 123456function fold (args, content) &#123; var text = args[0]; if(!text) text = "点击显/隐"; return '&lt;div&gt;&lt;div class="fold_hider"&gt;&lt;div class="close hider_title"&gt;' + text + '&lt;/div&gt;&lt;/div&gt;&lt;div class="fold"&gt;\n' + hexo.render.renderSync(&#123;text: content, engine: 'markdown'&#125;) + '\n&lt;/div&gt;&lt;/div&gt;';&#125;hexo.extend.tag.register('fold', fold, &#123;ends: true&#125;); themes/next/scripts/tags.js # 修复代码块显示问题点击显/隐代码 12345678910111213141516171819const rEscapeContent = /&lt;escape(?:[^&gt;]*)&gt;([\s\S]*?)&lt;\/escape&gt;/g;const placeholder = '\uFFFD';const rPlaceholder = /(?:&lt;|&amp;lt;)\!--\uFFFD(\d+)--(?:&gt;|&amp;gt;)/g;const cache = [];function escapeContent(str) &#123; return '&lt;!--' + placeholder + (cache.push(str) - 1) + '--&gt;';&#125;hexo.extend.filter.register('before_post_render', function(data) &#123; data.content = data.content.replace(rEscapeContent, function(match, content) &#123; return escapeContent(content); &#125;); return data;&#125;);hexo.extend.filter.register('after_post_render', function(data) &#123; data.content = data.content.replace(rPlaceholder, function() &#123; return cache[arguments[1]]; &#125;); return data;&#125;); themes/next/source/css/_custom/custom.styl # 样式点击显/隐代码 12345678910.hider_title&#123; font-family: "Microsoft Yahei"; cursor: pointer;&#125;.close:after&#123; content: "▼";&#125;.open:after&#123; content: "▲";&#125; Q19：Sidebar先显示再隐藏很喜欢Mist主题，但其侧边栏使得文章偏左，直接设置hide又担心读者不知道有目录存在，所以我添加了delay_hide选项，打开文章先展示侧边栏，然后隐藏在themes/next/source/js/src/post-details.js中添加如下代码即可123456789101112131415161718192021222324// Expand sidebar on post detail page by default, when post has a toc.var $tocContent = $('.post-toc-content');var isSidebarCouldDisplay = CONFIG.sidebar.display === 'post' || CONFIG.sidebar.display === 'always';var hasTOC = $tocContent.length &gt; 0 &amp;&amp; $tocContent.html().trim().length &gt; 0;if (isSidebarCouldDisplay &amp;&amp; hasTOC) &#123; CONFIG.motion.enable ? (NexT.motion.middleWares.sidebar = function () &#123; NexT.utils.displaySidebar(); &#125;) : NexT.utils.displaySidebar();&#125;// 以上是原有代码，新添加下面的代码const sleep = (milliseconds) =&gt; &#123;return new Promise(resolve =&gt; setTimeout(resolve, milliseconds))&#125;var isSidebarDelayHide = CONFIG.sidebar.display === 'delay_hide';if (isSidebarDelayHide &amp;&amp; hasTOC) &#123; NexT.utils.displaySidebar(); CONFIG.motion.enable ? (NexT.motion.middleWares.sidebar = function () &#123; NexT.utils.displaySidebar(); &#125;) : (sleep(1200).then(() =&gt; &#123; NexT.utils.displaySidebar() &#125;));&#125; Q20：主题自带样式 note 标签在themes/next/_config.yml中配置12345note: style: flat icons: true border_radius: 3 light_bg_offset: 0 使用如下：1&#123;% note %&#125;default&#123;% endnote %&#125; default 1&#123;% note primary %&#125;primary&#123;% endnote %&#125; primary 1&#123;% note success %&#125;success&#123;% endnote %&#125; success 1&#123;% note info %&#125;info&#123;% endnote %&#125; info 1&#123;% note warning %&#125;warning&#123;% endnote %&#125; warning 1&#123;% note danger %&#125;danger&#123;% endnote %&#125; danger 1&#123;% note danger no-icon %&#125;note without icon&#123;% endnote %&#125; note without icon Q21：主题自带样式 tabs 标签在themes/next/_config.yml中配置1234567# Tabs tag.tabs: enable: true transition: tabs: false labels: true border_radius: 0 使用如下：12345678&#123;% tabs tab, 1 %&#125;&lt;!-- tab --&gt;Text&lt;!-- endtab --&gt;&lt;!-- tab --&gt;Text&lt;!-- endtab --&gt;&#123;% endtabs %&#125; tab 1tab 2你注意到了么, 1表示默认展开第1个tabs 更多用法 Q22：Mist主题各种居中图片居中在themes/next/source/css/_custom/custom.styl文件中增加123.posts-expand &#123; .post-body img &#123; margin: 0 auto; &#125;&#125; 底部信息居中在themes/next/source/css/_custom/custom.styl文件中增加1234.footer-inner &#123; margin: 0 auto; text-align: center;&#125; 首页标题居中在themes/next/source/css/_custom/custom.styl文件中增加123.posts-expand .post-title, .posts-expand .post-meta, .posts-expand .post-button &#123; text-align: center;&#125; 标签居中在themes/next/source/css/_custom/custom.styl文件中增加123.posts-expand .post-tags &#123; text-align: center;&#125; 首页页码在themes/next/source/css/_custom/custom.styl文件中增加123.pagination &#123; text-align: center;&#125; Q23：博文置顶 解决Hexo置顶问题Hexo博客彻底解决置顶问题#415 12npm uninstall hexo-generator-index --savenpm install hexo-generator-index-pin-top --save 然后在需要置顶的文章的Front-matter中加上top: 1即可，数字越大越考前，数据相同根据时间排 设置置顶标志在themes/next/layout/_macro/post.swig文件中增加 12345678... ...&lt;div class="post-meta"&gt;+ &#123;% if post.top %&#125;+ &lt;font color=222222&gt;&lt;i class="fa fa-thumb-tack"&gt;&lt;/i&gt;&lt;/font&gt;+ &lt;span class="post-meta-divider"&gt;置顶 |&lt;/span&gt;+ &#123;% endif %&#125;&lt;span class="post-time"&gt;... ... 效果图 Q24：博文加密 MikeCoder/hexo-blog-encrypt 1npm install --save hexo-blog-encrypt 首先在站点_confid.yml中启用该插件123# Securityencrypt: enable: true 然后在需要加密的文章的Front-matter中加上对应的字段，如 password, abstract, message password: 是该博客加密使用的密码 abstract: 是该博客的摘要，会显示在博客的列表页 message: 这个是博客查看时，密码输入框上面的描述性文字 Q25：来必力评论点击加载 Hexo Next 主题点击加载 Disqus 和来必力双评论系统 修改以下两个文件即可/themes/next/layout/_partials/comments.swig1234567 &#123;% elseif theme.livere_uid %&#125; &lt;div class="comments" id="comments"&gt;+ &lt;div style="text-align:center;"&gt;+ &lt;button class="btn" id="load-livere" onclick="livere.load();"&gt;加载评论&lt;/button&gt;+ &lt;/div&gt; &lt;div id="lv-container" data-id="city" data-uid="&#123;&#123; theme.livere_uid &#125;&#125;"&gt;&lt;/div&gt; &lt;/div&gt; /themes/next/layout/_third-party/comments/livere.swig123456789101112131415161718192021222324&#123;% if not (theme.disqus.enable and theme.disqus.shortname) %&#125; &#123;% if page.comments and theme.livere_uid %&#125; &lt;script type="text/javascript"&gt;+ var livere = &#123;+ load : function livere() &#123; window.livereOptions = &#123; refer: '&#123;&#123; page.path &#125;&#125;' &#125;; (function(d, s) &#123; var j, e = d.getElementsByTagName(s)[0]; if (typeof LivereTower === 'function') &#123; return; &#125; j = d.createElement(s); j.src = 'https://cdn-city.livere.com/js/embed.dist.js'; j.async = true; e.parentNode.insertBefore(j, e); &#125;)(document, 'script');+ $('#load-livere').remove();+ &#125;+ &#125; &lt;/script&gt; &#123;% endif %&#125;&#123;% endif %&#125; Q26：Chatra在线聊天 注册账号，左侧Set up &amp; customize获取ChatraID以及进行样式定制 在/themes/next/layout/_custom/head.swig中加入以下代码 12345678910111213141516&lt;!-- Chatra &#123;literal&#125; --&gt;&#123;% if theme.chatra %&#125; &lt;script&gt; (function(d, w, c) &#123; w.ChatraID = "&#123;&#123;theme.chatra_app_id&#125;&#125;"; var s = d.createElement('script'); w[c] = w[c] || function() &#123; (w[c].q = w[c].q || []).push(arguments); &#125;; s.async = true; s.src = 'https://call.chatra.io/chatra.js'; if (d.head) d.head.appendChild(s); &#125;)(document, window, 'Chatra'); &lt;/script&gt;&#123;% endif %&#125;&lt;!-- /Chatra &#123;/literal&#125; --&gt; 在/themes/next/_config.yml中进行配置 12chatra: truechatra_app_id: your_chatra_app_id Chatra会拖慢网站的访问速度，受点击加载评论的启发，实现点击加载Chatra 1234567891011121314151617181920212223242526&lt;!-- Chatra &#123;literal&#125; --&gt;&#123;% if theme.chatra %&#125;+ &lt;div style="position: fixed; bottom: 10px; left: -2px; z-index: 9999;"&gt;+ &lt;button id="load-chatra" onclick="chatra.load();"&gt;+ &lt;i class="menu-item-icon fa fa-fw fa-commenting"&gt;&lt;/i&gt;+ &lt;/button&gt;+ &lt;/div&gt; &lt;script&gt;+ var chatra = &#123;+ load : function chatra() &#123; (function(d, w, c) &#123; w.ChatraID = "&#123;&#123;theme.chatra_app_id&#125;&#125;"; var s = d.createElement('script'); w[c] = w[c] || function() &#123; (w[c].q = w[c].q || []).push(arguments); &#125;; s.async = true; s.src = 'https://call.chatra.io/chatra.js'; if (d.head) d.head.appendChild(s); &#125;)(document, window, 'Chatra');+ $('#load-chatra').remove();+ &#125;+ &#125; &lt;/script&gt;&#123;% endif %&#125;&lt;!-- /Chatra &#123;/literal&#125; --&gt; 顺便定制一下按钮样式 12- &lt;button id="load-chatra" onclick="chatra.load();"&gt;+ &lt;button class="btn-chat" id="load-chatra" onclick="chatra.load();"&gt; 同时在themes/next/source/css/_custom/custom.styl中定制 123456789101112.btn-chat &#123; display: inline-block; font-size: $btn-default-font-size; color: $btn-default-color; background: #fff; border: 1px solid #555; text-decoration: none; border-radius: 4px; transition-property: background-color; the-transition(); line-height: 2;&#125; Q27：添加视频B站视频Hexo内置了标签插件可以插入Youtube视频1&#123;% youtube video_id %&#125; 但好像没有内置Bilibili，可以使用iframe插件插入，但显然大小位置不太对，最后我简单粗暴地直接整段代码写在文章里1&lt;div style="position: relative; width: 100%; height: 0; padding-bottom: 75%;"&gt;&lt;iframe src="//player.bilibili.com/player.html?aid=45011210&amp;cid=78831116&amp;page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"&gt; &lt;/iframe&gt;&lt;/div&gt; 其中的aid是video_id，就是av45011210后面这串数字，cid在源码里搜索aid=45011210就能找到 突然发现在分享里就有嵌入代码，蠢 本地视频 安装插件npm install hexo-tag-dplayer --save 在themes/next/source/css/_custom/custom.styl中定制央视 12345.dplayer-video-container &#123; max-width: 800px; margin: 0 auto; margin-top: -1rem;&#125; 嵌入代码，详细参数看GitHub 123456&lt;div class="dplayer-video-container"&gt; &#123;% dplayer "url=/video/26_mathtype.mp4" "pic=/video/26_mathtype.jpg" "loop=yes" "theme=#FADFA3" "autoplay=false" %&#125;&lt;/div&gt;]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编码与解码]]></title>
    <url>%2F20161029%2F3_encode_decode%2F</url>
    <content type="text"><![CDATA[【个人GitBook搬运】解除你对编码解码的困惑 字符串和编码-廖雪峰 字符编码 编码 语言 ASCII GB2312/GBK/GB18030 中文 Shift_JIS 日文 Euc-kr 韩文 使用unicode统一编码解决乱码问题 代价是，在英文上，unicode编码比ASCII编码多一倍存储 UTF-8编码把一个unicode字符根据不同的数字大小编码成1-6个字节，常用的英文字母被编码成1个字节，汉字通常是3个字节，只有很生僻的字符才会被编码成4-6个字节。 如果我们把所有现有的中、日、韩三国编码的非ASCII字符文本数据转换成UTF-8编码，则其大小都会变成原来的1.5倍。 一般情况下，记事本使用utf-8存储.txt文件，读取时转化为unicode编码显示；浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器 python编码 对于单个字符的编码，Python提供了ord()函数获取字符的整数表示，chr()函数把编码转换为对应的字符 u&#39;中&#39;等价于u&#39;\u4e2d&#39;u&#39;A&#39;等价于u&#39;\u0041&#39; unicode转utf-8(采用utf-8编码) 12&gt;&gt;&gt; u'中文'.encode('utf-8')'\xe4\xb8\xad\xe6\x96\x87' str.encode(encoding=&#39;UTF-8&#39;,errors=&#39;strict&#39;)strict: 抛异常ignore: 忽略异常replace: 替换（可用于查错）xmlcharrefreplace: 用适当的XML字符引用替换(仅用于encode)backslashreplace: 用反斜杠转义序列(仅用于encode)通过 codecs.register_error() 注册的任何值 utf-8转unicode(解码成unicode) 12&gt;&gt;&gt; print '\xe4\xb8\xad\xe6\x96\x87'.decode('utf-8')中文 12str --- decode方法 ---&gt; unicodeunicode --- encode方法 ---&gt; str # -*- coding: utf-8 -*-由于Python源代码也是一个文本文件，所以，当你的源代码中包含中文的时候，在保存源代码时，就需要务必指定保存为UTF-8编码。当Python解释器读取源代码时，为了让它按UTF-8编码读取，我们通常在文件开头写上这两行： 12#!/usr/bin/env python# -*- coding: utf-8 -*- 第一行注释是为了告诉Linux/OS X系统，这是一个Python可执行程序，Windows系统会忽略这个注释；第二行注释是为了告诉Python解释器，按照UTF-8编码读取源代码，否则，你在源代码中写的中文输出可能会有乱码。 sys模块设置默认编码可以省去很多麻烦，默认编码为ascii12345#coding:utf-8import sysreload(sys)sys.setdefaultencoding("utf-8")sys.getdefaultencoding() # 查看默认编码 print repr()通过print repr()可以查看python字符串的真实面貌 codecs 模块1234import codecsfp1 = codecs.open(filename,'w')fp2 = codecs.open(filename, 'r', 'utf-8')lines = fp2.readlins() raw_unicode_escape我们会遇到这样的情况：12&gt;&gt;&gt; print u'\xb5\xda\xd2\xbb\xbe\xed'.decode('gb2312')UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-5: ordinal not in range(128) 其实目的是想把字符串用gb2312解码：12&gt;&gt;&gt; print '\xb5\xda\xd2\xbb\xbe\xed'.decode('gb2312')第一卷 raw_unicode_escape可以帮我们去掉unicode前面的u12&gt;&gt;&gt; print u'\xb5\xda\xd2\xbb\xbe\xed'.encode('raw_unicode_escape').decode('gb2312')第一卷 附 Unicode和Python的中文处理 详解 python 中文编码与处理 来源：知乎 很久很久以前，有一群人，他们决定用8个可以开合的晶体管来组合成不同的状态，以表示世界上的万物。他们看到8个开关状态是好的，于是他们把这称为”字节“。再后来，他们又做了一些可以处理这些字节的机器，机器开动了，可以用字节来组合出很多状态，状态开始变来变去。他们看到这样是好的，于是它们就这机器称为”计算机“。 开始计算机只在美国用。八位的字节一共可以组合出256(2的8次方)种不同的状态。 他们把其中的编号从0开始的32种状态分别规定了特殊的用途，一但终端、打印机遇上约定好的这些字节被传过来时，就要做一些约定的动作。遇上0×10, 终端就换行，遇上0×07, 终端就向人们嘟嘟叫，例好遇上0x1b, 打印机就打印反白的字，或者终端就用彩色显示字母。他们看到这样很好，于是就把这些0×20以下的字节状态称为”控制码”。他们又把所有的空 格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的文字了。大家看到这样，都感觉 很好，于是大家都把这个方案叫做ANSI 的”Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。当时世界上所有的计算机都用同样的ASCII方案来保存英文文字。 后来，就像建造巴比伦塔一样，世界各地的都开始使用计算机，但是很多国家用的不是英文，他们的字母里有许多是ASCII里没有的，为了可以在计算机保存他们的文字，他们决定采用 127号之后的空位来表示这些新的字母、符号，还加入了很多画表格时需要用下到的横线、竖线、交叉等形状，一直把序号编到了最后一个状态255。从128 到255这一页的字符集被称”扩展字符集“。从此之后，贪婪的人类再没有新的状态可以用了，美帝国主义可能没有想到还有第三世界国家的人们也希望可以用到计算机吧！ 等中国人们得到计算机时，已经没有可以利用的字节状态来表示汉字，况且有6000多个常用汉字需要保存呢。但是这难不倒智慧的中国人民，我们不客气地把那些127号之后的奇异符号们直接取消掉, 规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，我们还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。 中国人民看到这样很不错，于是就把这种汉字方案叫做 “GB2312“。GB2312 是对 ASCII 的中文扩展。 但是中国的汉字太多了，我们很快就就发现有许多人的人名没有办法在这里打出来，特别是某些很会麻烦别人的国家领导人。于是我们不得不继续把 GB2312 没有用到的码位找出来老实不客气地用上。 后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，不管后面跟的是不是扩展字符集里的内容。结果扩展之后的编码方案被称为 GBK 标准，GBK包括了GB2312 的所有内容，同时又增加了近20000个新的汉字（包括繁体字）和符号。 后来少数民族也要用电脑了，于是我们再扩展，又加了几千个新的少数民族的字，GBK扩成了 GB18030。从此之后，中华民族的文化就可以在计算机时代中传承了。 中国的程序员们看到这一系列汉字编码的标准是好的，于是通称他们叫做 “DBCS“（Double Byte Charecter Set 双字节字符集）。在DBCS系列标准里，最大的特点是两字节长的汉字字符和一字节长的英文字符并存于同一套编码方案里，因此他们写的程序为了支持中文处理，必须要注意字串里的每一个字节的值，如果这个值是大于127的，那么就认为一个双字节字符集里的字符出现了。那时候凡是受过加持，会编程的计算机僧侣 们都要每天念下面这个咒语数百遍： “一个汉字算两个英文字符！一个汉字算两个英文字符……” 因为当时各个国家都像中国这样搞出一套自己的编码标准，结果互相之间谁也不懂谁的编码，谁也不支持别人的编码，连大陆和台湾这样只相隔了150海里，使用着同一种语言的兄弟地区，也分别采用了不同的 DBCS 编码方案——当时的中国人想让电脑显示汉字，就必须装上一个”汉字系统”，专门用来处理汉字的显示、输入的问题，但是那个台湾的愚昧封建人士写的算命程序就必须加装另一套支持 BIG5 编码的什么”倚天汉字系统”才可以用，装错了字符系统，显示就会乱了套！这怎么办？而且世界民族之林中还有那些一时用不上电脑的穷苦人民，他们的文字又怎么办？ 真是计算机的巴比伦塔命题啊！ 正在这时，大天使加百列及时出现了——一个叫 ISO （国际标谁化组织）的国际组织决定着手解决这个问题。他们采用的方法很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号 的编码！他们打算叫它”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “unicode“。unicode开始制订时，计算机的存储器容量极大地发展了，空间再也不成为问题了。于是 ISO 就直接规定必须用两个字节，也就是16位来统一表示所有的字符，对于ASCII里的那些“半角”字符，unicode包持其原编码不变，只是将其长度由原来的8位扩展为16位，而其他文化和语言的字符则全部重新统一编码。由于”半角”英文符号只需要用到低8位，所以其高8位永远是0，因此这种大气的方案在保存英文文本时会多浪费一倍的空间。 这时候，从旧社会里走过来的程序员开始发现一个奇怪的现象：他们的strlen函数靠不住了，一个汉字不再是相当于两个字符了，而是一个！是的，从unicode开始，无论是半角的英文字母，还是全角的汉字，它们都是统一的”一个字符“！同时，也都是统一的”两个字节“，请注意”字符”和”字节”两个术语的不同，“字节”是一个8位的物理存贮单元，而“字符”则是一个文化相关的符号。在unicode中，一个字符就是两个字节。一个汉字算两个英文字符的时代已经快过去了。 unicode同样也不完美，这里就有两个的问题，一个是，如何才能区别unicode和ascii？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储空间来说是极大的浪费，文本文件的大小会因此大出二三倍，这是难以接受的。 unicode在很长一段时间内无法推广，直到互联网的出现，为解决unicode如何在网络上传输的问题，于是面向传输的众多 UTF（UCS Transfer Format）标准出现了，顾名思义，UTF-8就是每次8个位传输数据，而UTF-16就是每次16个位。UTF-8就是在互联网上使用最广的一种unicode的实现方式，这是为传输而设计的编码，并使编码无国界，这样就可以显示全世界上所有文化的字符了。 UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度，当字符在ASCII码的范围时，就用一个字节表示，保留了ASCII字符一个字节的编码做为它的一部分，注意的是unicode一个中文字符占2个字节，而UTF-8一个中文字符占3个字节）。从unicode到uft-8并不是直接的对应，而是要过一些算法和规则来转换。 Unicode符号范围 UTF-8编码方式 (十六进制) （二进制） 0000 0000-0000 007F 0xxxxxxx 0000 0080-0000 07FF 110xxxxx 10xxxxxx 0000 0800-0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx 0001 0000-0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python Tips]]></title>
    <url>%2F20161026%2F2_python_tips%2F</url>
    <content type="text"><![CDATA[【个人GitBook搬运】python使用的小Tips 读写操作 使用codecs模块 1234import codecsfp1 = codecs.open(filename,'w')fp2 = codecs.open(filename, 'r', 'utf-8')lines = fp2.readlins() 文件关闭 123456try:f = open('/path/to/file', 'r')print f.read()finally:if f:f.close() 更简洁的表达：12with open('/path/to/file', 'r') as f:print f.read() read()&amp;readline()&amp;readlines() read()一次性读取文件的全部内容,read(size)每次最多读取size个字节的内容 readline()可以每次读取一行内容 readlines()一次读取所有内容并按行返回list 总结123import codecswith codecs.open('/Users/michael/gbk.txt', 'r', 'gbk') as f:f.read() 文件操作shutil.copytree(windowsDir, photoDir) 工作目录123import oscurDir = os.getcwd() #获取当前工作目录chDir = os.chdir(path) # 更改工作目录 defaultdict &amp; dict = {}dict = defaultdict(default_factory)就是一个字典，只不过python自动为其键值赋上初值 123456789101112131415&gt;&gt;&gt; s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]&gt;&gt;&gt; d = defaultdict(list)&gt;&gt;&gt; for k, v in s:... d[k].append(v)...&gt;&gt;&gt; d.items()[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]&gt;&gt;&gt; s = 'mississippi'&gt;&gt;&gt; d = defaultdict(int)&gt;&gt;&gt; for k in s:... d[k] += 1...&gt;&gt;&gt; d.items()[('i', 4), ('p', 2), ('s', 4), ('m', 1)] list12[word for word in wordlist if word != '*'] # 生成列表for i,e in enumerate(list): # 取出列表元素以及所在位置 下划线的使用 详解Python中的下划线Python单下划线/双下划线使用总结1234object # public__object__ # special, python system use, user should not define like it__object # private (name mangling during runtime)_object # obey python coding convention, consider it as private 单下划线开始的成员变量叫做保护变量，意思是只有类对象和子类对象自己能访问到这些变量 双下划线开始的是私有成员，意思是只有类对象自己能访问，连子类对象也不能访问到这个数据。 以单下划线开头_foo的代表不能直接访问的类属性，需通过类提供的接口进行访问，不能用from xxx import *而导入 以双下划线开头的__foo代表类的私有成员 以双下划线开头和结尾的__foo__代表python里特殊方法专用的标识，如 __init__()代表类的构造函数。 内存释放先del，再显式调用gc.collect() 123import gcdel listgc.collect() conda基础使用 conda create --name env_name python=3.6 activate env_name or source activate env_name deactivate env_name or source deactivate env_name conda remove --nme env_name --all conda info -e conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ and conda config --set show_channel_urls yes 使用镜像提升pip下载速度 让PIP源使用国内镜像，提升下载速度和安装成功率 pypi 镜像使用帮助 window在C:\Users\user_name下创建pip/pip.ini文件，文件内容为： 1234[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host=mirrors.aliyun.com pass]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Tips]]></title>
    <url>%2F20160930%2F1_linux_tips%2F</url>
    <content type="text"><![CDATA[【个人GitBook搬运】Linux使用过程中的一些小Tips 双系统修改开机引导1sudo vim /boot/grub/grub.cfg set default=”0”修改为set default=”x”——x为第x个选项，Ubuntu下一般为4 set timeout=10修改为set timeout=3——默认三秒 vim下通过”/“查找，”n”寻找下一个，修改查找到的第一个set timeout=10 环境变量 /etc/environment:此文件为整个系统设置环境信息，用户登陆是执行。 /etc/profile：此文件为系统的每个用户设置环境信息，用户登陆是执行。 /etc/bashrc:此文件为系统的shell终端设置环境信息，shell打开是执行。 ~/.profile(~/.bash_profile):单用户生效的profile ~/.bashrc:单用户生效的bashrc 使用source /etc/environment可以使变量设置在当前窗口立即生效，需注销/重启之后，才能对每个新终端窗口都生效。 错误修改/etc/environment导致无法开机修复 alt +ctrl+f1进入命令模式 1/usr/bin/sudo /usr/bin/vi /etc/environment 删除多余export PATH或修复PATH 1PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games&quot; 退出vi并重启系统 1/usr/bin/sudo /sbin/reboot JAVA安装 推荐教程 Oracle JDK下载 解压并放在/usr/lib/java 123sudo mkdir /usr/lib/javasudo mv /home/zydar/下载/jdk* /usr/lib/javasudo tar -xvf jdk-* 配置/etc/profile环境变量 123456JAVA_HOME=/usr/lib/java/jdk1.8.0_101JRE_HOME=$JAVA_HOME/jrePATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOMEexport JRE_HOMEexport PATH 使修改生效 1source /etc/profile 验证 1java -version PPA(Personal Package Archives) 添加PPA1sudo add-apt-repository ppa:user/ppa-name 方法一：设置-&gt;软件和更新-&gt;其他软件-&gt;添加-&gt;输入ppa:user/ppa-name 更新源地址 1sudo apt-get update 删除PPA 1sudo add-apt-repository -r ppa:user/ppa-name 方法二：设置-&gt;软件和更新-&gt;其他软件-&gt;选中删除 e.g.使用PPA安装flux1234sudo add-apt-repository ppa:nathan-renniewaldock/fluxsudo apt-get updatesudo apt-get install fluxguisudo /usr/bin/fluxgui 安装搜狗输入法 下载deb包 双击安装 语言设置里把默认输入法改为fcitx 选择“应用到整个系统” 重启，完成 下载.ssf皮肤文件，双击安装皮肤 Ubuntu安装wine-qqintl 下载ZIP 安装32位依赖库 12sudo apt-get install libgtk2.0-0:i386sudo apt-get install -f 解压ZIP，cd进入wine-qqintl 安装 123sudo dpkg -i wine-qqintl_0.1.3-2_i386.debsudo dpkg -i ttf-wqy-microhei_0.2.0-beta-2_all.debsudo dpkg -i fonts-wqy-microhei_0.2.0-beta-2_all.deb Dash中搜索QQ，点击启动 不要试图修改默认设置 不要试图修改默认设置 不要试图修改默认设置 安装扁平主题Flatabulous Flatabulous:超级好看的Ubuntu扁平主题GitHub上官方文档 安装Unity Tweak Tool 1sudo apt-get install unity-tweak-tool 下载Flatabulous源码 1git clone https://github.com/anmoljagetia/Flatabulous 或到GitHub上下载ZIP 移动到/usr/share/themes/下 1sudo mv Flatabulous /usr/share/themes/ 安装扁平图标 123sudo add-apt-repository ppa:noobslab/iconssudo apt-get updatesudo apt-get install ultra-flat-icons Dash中启动Unity Tweak Tool，修改主题与图标 sublime text 3安装与中文兼容优化内存 swappiness=0的时候表示最大限度使用物理内存，然后才是 swap空间，swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。两个极端，对于ubuntu的默认设置，这个值等于60，建议修改为10。 1234cat /proc/sys/vm/swappiness # 查看swappiness，默认60sudo sysctl vm.swappiness=10 # 临时修改sudo gedit /etc/sysctl.conf文档末尾追加vm.swappiness=10 Ubuntu图形界面卡死 重启 关闭图形界面 ctrl+alt+f1转到tty1 ps -t tty7查看进程号 找到Xorg进程的PID号xxx sudo kill xxx 关闭卡死进程 检测到系统程序出现问题 sudo rm /var/crash/*]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark搭建]]></title>
    <url>%2F20160927%2F0_spark_build%2F</url>
    <content type="text"><![CDATA[【个人GitBook搬运】本地搭建Spark JAVA安装与环境搭建ssh安装与测试 单机Spark可略过略 hadoop安装与配置（可跳过） Apache Hadoop下载（binary文件） 解压放到/home/zydar/software下(不建议放在/usr下) 配置JAVA_HOME 12#export JAVA_HOME=$&#123;JAVA_HOME&#125;export JAVA_HOME=/usr/lib/java/jdk1.8.0_101 配置/etc/profile：export HADOOP_HOME,PATH追加:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 12345678JAVA_HOME=/usr/lib/java/jdk1.8.0_101JRE_HOME=$JAVA_HOME/jreHADOOP_HOME=/usr/local/bin/hadoop-2.7.3PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/binexport JAVA_HOMEexport JRE_HOMEexport HADOOP_HOMEexport PATH 验证 1hadoop version wordcount测试 1234567cd $HADOOP_HOMEsudo mkdir inputcp etc/hadoop/* inputhadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount input /home/zydar/outputcat /home/zydar/output/*rm -r /home/zydar/outputrm -r input 伪分布Hadoop配置 配置core-site.xml，hdfs-site.xml，yarn-site.xml，mapred-site.xml 123456789101112131415161718192021222324252627282930313233343536【core-site.xml】&lt;configuration&gt;&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://localhost:8082&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;【hdfs-site.xml】&lt;configuration&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;&lt;value&gt;/usr/local/hadoop/hadoop-2.6.4/dfs/name&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;&lt;value&gt;/usr/local/hadoop/hadoop-2.6.4/dfs/data&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;【yarn-site.xml】&lt;configuration&gt;&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux.services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;【mapred-site.xml】(cp mapred-site.xml.template mapred-site.xml)&lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapreduce.framwork.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 格式化 1bin/hadoop namenode -format 启动/关闭hadoop 1start-all.sh/stop-all.sh jps查看JAVA进程 查看hadoop localhost:50070localhost:8088/clusterhdfs dfsadmin -report 伪分布wordcount测试123456hdfs dfs -mkdir -p inputhdfs dfs -put etc/hadoop inputhadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar wordcount input/hadoop outputhdfs dfs -cat output/*hdfs dfs -rm -r inputhdfs dfs -rm -r output Spark安装与配置 Spark下载 解压放到/home/zydar/software下(不建议放在/usr下) 配置/etc/profile：export SPARK_HOME,PATH追加:$SPARK_HOME/bin 配置环境 12cp ./conf/spark-env.sh.template ./conf/spark-env.shvim ./conf/spark-env.sh export JAVA_HOME=/usr/lib/java/jdk1.8.0_101export SPARK_MASTER_IP=125.216.238.149export SPARK_WORKER_MEMORY=2gexport HADOOP_CONF_DIR=/home/zydar/software/hadoop-2.7.3/etc/hadoop 启动Spark 1./sbin/start-all.sh localhost:8080查看Spark集群 新建job（localhost:4040）1234pyspark --master spark://zydar-HP:7077 --name czh --executor-memory 1G --total-executor-cores 2&gt;&gt;&gt; textFile = sc.textFile(&quot;file:///home/zydar/software/spark-2.0.0/README.md&quot;)&gt;&gt;&gt; textFile.count()&gt;&gt;&gt; textFile.filter(lambda line: line.split(&apos; &apos;)).map(lambda word: (word,1)).reduceByKey(lambda a,b: a+b).map(lambda (a,b): (b,a)).sortByKey(False).map(lambda (a,b): (b,a)).collect() Spark IDE开发环境 配置/etc/profile：export PYTHONPATH1PYTHONPATH=$PYTHONPATH:$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.1-src.zip Spark on Pycharm 下载Python（推荐.edu账号注册免费使用Professional版） 解压放到/home/zydar/software下(不建议放在/usr下) 运行 1./bin/pycharm.sh 测试代码 123456789from pyspark import SparkContext,SparkConf#conf = SparkConf().setAppName(&quot;YOURNAME&quot;).setMaster(&quot;local[*]&quot;)conf = SparkConf().setAppName(&quot;YOURNAME&quot;).setMaster(&quot;spark://zydar-HP:7077&quot;).set(&quot;spark.executor.memory&quot;, &quot;1g&quot;).set(&quot;spark.cores.max&quot;, &quot;2&quot;)sc = SparkContext(conf=conf)localFile = &quot;file:///home/zydar/software/spark-2.0.0/README.md&quot;hdfsFile = &quot;README.md&quot;hdfsFile1 = &quot;/user/zydar/README.md&quot;textFile = sc.textFile(localFile)print textFile.count() Spark配置（官方） Spark on Ipython Notebook Ipython Notebook安装与配置 123apt-get install ipython#安装ipythonapt-get install ipython-notebook#安装ipython notebookipython profile create spark#创建spark的config 记下生成的路径/home/zydar/.ipython/profile_spark/ipython_notebook_config.py 进入ipython设置密码 123ipythonIn [1]:from IPython.lib import passwdIn [2]:passwd() 记下返回的sha1 进入ipython_notebook_config.py文件 123c.NotebookApp.password = u&apos;sha1:67c34dbbc0f8:a96f9c64adbf4c58f2e71026a4bffb747d777c5a&apos;c.FileNotebookManager.notebook_dir = u&apos;/home/zydar/software/data/ipythonNotebook&apos;# c.NotebookApp.open_browser = False 打开Ipython Notebook 1ipython notebook --profile=spark 测试代码（同Pycharm）]]></content>
      <categories>
        <category>工具使用</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
</search>
